{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_IlY1GnV83T3"
   },
   "source": [
    "# 2020语言与智能技术竞赛：机器阅读理解任务\n",
    "https://aistudio.baidu.com/aistudio/competition/detail/28\n",
    "\n",
    "\n",
    "平台提供的数据为JSON文件格式，样例如下:\n",
    "\n",
    "    {\n",
    "        \"data\": [\n",
    "            {\n",
    "                \"paragraphs\": [\n",
    "                    {\n",
    "                        \"qas\": [\n",
    "                            {\n",
    "                                \"question\": \"非洲气候带\", \n",
    "                                \"id\": \"bd664cb57a602ae784ae24364a602674\", \n",
    "                                \"answers\": [\n",
    "                                    {\n",
    "                                        \"text\": \"热带气候\", \n",
    "                                        \"answer_start\": 45\n",
    "                                    }\n",
    "                                ]\n",
    "                            }\n",
    "                        ], \n",
    "                        \"context\": \"1、全年气温高，有热带大陆之称。主要原因在与赤道穿过大陆中部，位于南北纬30度之间，主要是热带气候，没有温带和寒带… \n",
    "                    }, \n",
    "                    {\n",
    "                        \"qas\": [\n",
    "                            {\n",
    "                                \"question\": \"韩国全称\", \n",
    "                                \"id\": \"a7eec8cf0c55077e667e0d85b45a6b34\", \n",
    "                                \"answers\": [\n",
    "                                    {\n",
    "                                        \"text\": \"大韩民国\", \n",
    "                                        \"answer_start\": 5\n",
    "                                    }\n",
    "                                ]\n",
    "                            }\n",
    "                        ], \n",
    "                        \"context\": \"韩国全称“大韩民国”，位于朝鲜半岛南部，隔“三八线”与朝鲜民主主义人民共和国相邻，面积9.93万平方公理… \"\n",
    "                    }\n",
    "                ], \n",
    "                \"title\": \"\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ENz-l7O683T4"
   },
   "source": [
    "* 百度LIC2020的机器阅读理解赛道，非官方baseline\n",
    "* 直接用RoBERTa+Softmax预测首尾\n",
    "* BASE模型在第一期测试集上能达到0.69的F1，优于官方baseline\n",
    "* 如果你显存足够，可以换用RoBERTa Large模型，F1可以到0.71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 155
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5805,
     "status": "ok",
     "timestamp": 1599328418851,
     "user": {
      "displayName": "Nelson LIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgrEZmWMjk_h9SZRyH_-oJW-4yrQ19ywOKCx8EA=s64",
      "userId": "03694478629413699942"
     },
     "user_tz": -480
    },
    "id": "b4aRVkx883T4",
    "outputId": "26cd908e-a26d-473f-d949-0861323b7429"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/4a/39400ff9b36e719bdf8f31c99fe1fa7842a42fa77432e584f707a5080063/pip-20.2.2-py2.py3-none-any.whl (1.5MB)\n",
      "\r",
      "\u001b[K     |▏                               | 10kB 15.1MB/s eta 0:00:01\r",
      "\u001b[K     |▍                               | 20kB 2.2MB/s eta 0:00:01\r",
      "\u001b[K     |▋                               | 30kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |▉                               | 40kB 3.1MB/s eta 0:00:01\r",
      "\u001b[K     |█                               | 51kB 2.5MB/s eta 0:00:01\r",
      "\u001b[K     |█▎                              | 61kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█▌                              | 71kB 3.0MB/s eta 0:00:01\r",
      "\u001b[K     |█▊                              | 81kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 92kB 3.6MB/s eta 0:00:01\r",
      "\u001b[K     |██▏                             | 102kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██▍                             | 112kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██▋                             | 122kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██▉                             | 133kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 143kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███▎                            | 153kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███▌                            | 163kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███▊                            | 174kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 184kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████▏                           | 194kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████▍                           | 204kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████▋                           | 215kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████▉                           | 225kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 235kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████▎                          | 245kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████▌                          | 256kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████▋                          | 266kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████▉                          | 276kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 286kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████▎                         | 296kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████▌                         | 307kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████▊                         | 317kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 327kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████▏                        | 337kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████▍                        | 348kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 358kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 368kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 378kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████▎                       | 389kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████▌                       | 399kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████▊                       | 409kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 419kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▏                      | 430kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▍                      | 440kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▋                      | 450kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▉                      | 460kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 471kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 481kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▌                     | 491kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▊                     | 501kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 512kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▏                    | 522kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▎                    | 532kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▌                    | 542kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▊                    | 552kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 563kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▏                   | 573kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▍                   | 583kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▋                   | 593kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▉                   | 604kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 614kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 624kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▌                  | 634kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▊                  | 645kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 655kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▏                 | 665kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▍                 | 675kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▋                 | 686kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▉                 | 696kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 706kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▎                | 716kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▌                | 727kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▊                | 737kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 747kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▏               | 757kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▍               | 768kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▋               | 778kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▉               | 788kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 798kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▏              | 808kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▍              | 819kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▋              | 829kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▉              | 839kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 849kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▎             | 860kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▌             | 870kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▊             | 880kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 890kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▏            | 901kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▍            | 911kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▋            | 921kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▉            | 931kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 942kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▎           | 952kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▌           | 962kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▊           | 972kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 983kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▏          | 993kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▍          | 1.0MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▋          | 1.0MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▉          | 1.0MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 1.0MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▎         | 1.0MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▌         | 1.1MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 1.1MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▉         | 1.1MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 1.1MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▎        | 1.1MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▌        | 1.1MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▊        | 1.1MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 1.1MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▏       | 1.1MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▍       | 1.1MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▋       | 1.2MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▉       | 1.2MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 1.2MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▎      | 1.2MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▌      | 1.2MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▊      | 1.2MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 1.2MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▏     | 1.2MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▍     | 1.2MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▋     | 1.2MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▉     | 1.3MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 1.3MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▎    | 1.3MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▌    | 1.3MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▊    | 1.3MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 1.3MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 1.3MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▎   | 1.3MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▌   | 1.3MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▊   | 1.4MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 1.4MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 1.4MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▍  | 1.4MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▋  | 1.4MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▉  | 1.4MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 1.4MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 1.4MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▌ | 1.4MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▊ | 1.4MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 1.5MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 1.5MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▍| 1.5MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▋| 1.5MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▉| 1.5MB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 1.5MB 3.4MB/s \n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Found existing installation: pip 19.3.1\n",
      "    Uninstalling pip-19.3.1:\n",
      "      Successfully uninstalled pip-19.3.1\n",
      "Successfully installed pip-20.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "# !pip install bert4keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1033,
     "status": "ok",
     "timestamp": 1599328421120,
     "user": {
      "displayName": "Nelson LIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgrEZmWMjk_h9SZRyH_-oJW-4yrQ19ywOKCx8EA=s64",
      "userId": "03694478629413699942"
     },
     "user_tz": -480
    },
    "id": "9cr6v0WTVdcH"
   },
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4745,
     "status": "ok",
     "timestamp": 1599328425242,
     "user": {
      "displayName": "Nelson LIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgrEZmWMjk_h9SZRyH_-oJW-4yrQ19ywOKCx8EA=s64",
      "userId": "03694478629413699942"
     },
     "user_tz": -480
    },
    "id": "uYDEepj6B1sq",
    "outputId": "b303e40f-94a7-49a5-a68e-b98830414ddb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert4keras==0.7.7\n",
      "  Downloading bert4keras-0.7.7.tar.gz (37 kB)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from bert4keras==0.7.7) (2.4.3)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->bert4keras==0.7.7) (3.13)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->bert4keras==0.7.7) (1.18.5)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->bert4keras==0.7.7) (2.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->bert4keras==0.7.7) (1.4.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras->bert4keras==0.7.7) (1.15.0)\n",
      "Building wheels for collected packages: bert4keras\n",
      "  Building wheel for bert4keras (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for bert4keras: filename=bert4keras-0.7.7-py3-none-any.whl size=36805 sha256=270222c573212aaf95c14908066493a2edfa775469017981f2ff0bc70a0d582b\n",
      "  Stored in directory: /root/.cache/pip/wheels/fe/44/ad/947f4210d1d87fac2d67621c954ed556ecbd85cb374e346d4f\n",
      "Successfully built bert4keras\n",
      "Installing collected packages: bert4keras\n",
      "Successfully installed bert4keras-0.7.7\n"
     ]
    }
   ],
   "source": [
    "!pip install bert4keras==0.7.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2421,
     "status": "ok",
     "timestamp": 1599328428259,
     "user": {
      "displayName": "Nelson LIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgrEZmWMjk_h9SZRyH_-oJW-4yrQ19ywOKCx8EA=s64",
      "userId": "03694478629413699942"
     },
     "user_tz": -480
    },
    "id": "T_6c_DPF83T9"
   },
   "outputs": [],
   "source": [
    "import json, os\n",
    "import numpy as np\n",
    "from bert4keras.backend import keras, K\n",
    "from bert4keras.models import build_transformer_model\n",
    "from bert4keras.tokenizers import Tokenizer\n",
    "from bert4keras.optimizers import Adam\n",
    "from bert4keras.snippets import sequence_padding, DataGenerator\n",
    "from bert4keras.snippets import open\n",
    "from keras.layers import Layer, Dense, Permute\n",
    "from keras.models import Model\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 基本信息\n",
    "maxlen = 512\n",
    "epochs = 20\n",
    "batch_size = 4\n",
    "learing_rate = 2e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "63X9pOVw83T_"
   },
   "source": [
    "# 下载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 20199,
     "status": "ok",
     "timestamp": 1599328446871,
     "user": {
      "displayName": "Nelson LIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgrEZmWMjk_h9SZRyH_-oJW-4yrQ19ywOKCx8EA=s64",
      "userId": "03694478629413699942"
     },
     "user_tz": -480
    },
    "id": "W6NMYxpM9TPO",
    "outputId": "8b2f6f37-b859-453d-feed-6f1d7430be70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OfZrLiTm-hz7"
   },
   "source": [
    "## 解压"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 922,
     "status": "ok",
     "timestamp": 1599328449120,
     "user": {
      "displayName": "Nelson LIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgrEZmWMjk_h9SZRyH_-oJW-4yrQ19ywOKCx8EA=s64",
      "userId": "03694478629413699942"
     },
     "user_tz": -480
    },
    "id": "uaUwhtw19frG",
    "outputId": "8122db28-e06f-45f0-a82d-1f3ed71f0b1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demo\t  dev.json.pred.json  evluation_utils.py  __pycache__  train.json\n",
      "dev.json  evaluate.py\t      License.docx\t  README.md\n"
     ]
    }
   ],
   "source": [
    "!ls /content/drive/\"My Drive\"/\"Colab Notebooks\"/\"Machine Reading Comprehension\"/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4EIYmRCaA_nH"
   },
   "source": [
    "## 设置数据路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 599,
     "status": "ok",
     "timestamp": 1599328451638,
     "user": {
      "displayName": "Nelson LIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgrEZmWMjk_h9SZRyH_-oJW-4yrQ19ywOKCx8EA=s64",
      "userId": "03694478629413699942"
     },
     "user_tz": -480
    },
    "id": "ItUURTQ183UA"
   },
   "outputs": [],
   "source": [
    "data_dir=\"/content/drive/My Drive/Colab Notebooks/Machine Reading Comprehension/data\"\n",
    "output_dir='/content/drive/My Drive/Colab Notebooks/Machine Reading Comprehension/data/output/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pKJKHQkz83UP"
   },
   "source": [
    "# 模型路径"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert 预训练模型：https://github.com/google-research/bert#pre-trained-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 589,
     "status": "ok",
     "timestamp": 1599328454266,
     "user": {
      "displayName": "Nelson LIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgrEZmWMjk_h9SZRyH_-oJW-4yrQ19ywOKCx8EA=s64",
      "userId": "03694478629413699942"
     },
     "user_tz": -480
    },
    "id": "NcK7H86G83UT"
   },
   "outputs": [],
   "source": [
    "bert_dir = '/content/drive/My Drive/Colab Notebooks/Machine Reading Comprehension/baseline_model'\n",
    "config_path = f'{bert_dir}/bert_config.json'\n",
    "checkpoint_path = f'{bert_dir}/bert_model.ckpt'\n",
    "dict_path = f'{bert_dir}/vocab.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DWUGIH8T83UV"
   },
   "source": [
    "# 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 570,
     "status": "ok",
     "timestamp": 1599328456252,
     "user": {
      "displayName": "Nelson LIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgrEZmWMjk_h9SZRyH_-oJW-4yrQ19ywOKCx8EA=s64",
      "userId": "03694478629413699942"
     },
     "user_tz": -480
    },
    "id": "vjf9nl7I83UW"
   },
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    D = []\n",
    "    for d in json.load(open(filename))['data'][0]['paragraphs']:\n",
    "        for qa in d['qas']:\n",
    "            D.append([\n",
    "                qa['id'], d['context'], qa['question'],\n",
    "                [a['text'] for a in qa.get('answers', [])]\n",
    "            ])\n",
    "    return D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IorbHPdP83UY"
   },
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 470,
     "status": "ok",
     "timestamp": 1599328475679,
     "user": {
      "displayName": "Nelson LIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgrEZmWMjk_h9SZRyH_-oJW-4yrQ19ywOKCx8EA=s64",
      "userId": "03694478629413699942"
     },
     "user_tz": -480
    },
    "id": "w70wRIw883UY"
   },
   "outputs": [],
   "source": [
    "train_data = load_data(\n",
    "    # os.path.join(data_dir,'train.json')\n",
    "    os.path.join(data_dir,'demo/demo_train.json')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k2SDWmUv83Ua"
   },
   "source": [
    "# 建立分词器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1218,
     "status": "ok",
     "timestamp": 1599328497452,
     "user": {
      "displayName": "Nelson LIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgrEZmWMjk_h9SZRyH_-oJW-4yrQ19ywOKCx8EA=s64",
      "userId": "03694478629413699942"
     },
     "user_tz": -480
    },
    "id": "8G1BqYjh83Ub"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(dict_path, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K399Sc5E83Ud"
   },
   "source": [
    "# 子串搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1660,
     "status": "ok",
     "timestamp": 1599328500190,
     "user": {
      "displayName": "Nelson LIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgrEZmWMjk_h9SZRyH_-oJW-4yrQ19ywOKCx8EA=s64",
      "userId": "03694478629413699942"
     },
     "user_tz": -480
    },
    "id": "C2Y8mXlE83Ue"
   },
   "outputs": [],
   "source": [
    "def search(pattern, sequence):\n",
    "    \"\"\"从sequence中寻找子串pattern\n",
    "    如果找到，返回第一个下标；否则返回-1。\n",
    "    \"\"\"\n",
    "    n = len(pattern)\n",
    "    for i in range(len(sequence)):\n",
    "        if sequence[i:i + n] == pattern:\n",
    "            return i\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QHMtsGYC83Uh"
   },
   "source": [
    "# 数据生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1231,
     "status": "ok",
     "timestamp": 1599328502969,
     "user": {
      "displayName": "Nelson LIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgrEZmWMjk_h9SZRyH_-oJW-4yrQ19ywOKCx8EA=s64",
      "userId": "03694478629413699942"
     },
     "user_tz": -480
    },
    "id": "fypxJpY583Uh"
   },
   "outputs": [],
   "source": [
    "class data_generator(DataGenerator):\n",
    "    def __iter__(self, random=False):\n",
    "        batch_token_ids, batch_segment_ids, batch_labels = [], [], []\n",
    "        for is_end, item in self.sample(random):\n",
    "            context, question, answers = item[1:]\n",
    "            token_ids, segment_ids = tokenizer.encode(\n",
    "                question, context, max_length=maxlen\n",
    "            )\n",
    "            a = np.random.choice(answers)\n",
    "            a_token_ids = tokenizer.encode(a)[0][1:-1]\n",
    "            start_index = search(a_token_ids, token_ids)\n",
    "            if start_index != -1:\n",
    "                labels = [[start_index], [start_index + len(a_token_ids) - 1]]\n",
    "                batch_token_ids.append(token_ids)\n",
    "                batch_segment_ids.append(segment_ids)\n",
    "                batch_labels.append(labels)\n",
    "                if len(batch_token_ids) == self.batch_size or is_end:\n",
    "                    batch_token_ids = sequence_padding(batch_token_ids)\n",
    "                    batch_segment_ids = sequence_padding(batch_segment_ids)\n",
    "                    batch_labels = sequence_padding(batch_labels)\n",
    "                    yield [batch_token_ids, batch_segment_ids], batch_labels\n",
    "                    batch_token_ids, batch_segment_ids, batch_labels = [], [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fvx3sVXK83Uj"
   },
   "source": [
    "# Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1447,
     "status": "ok",
     "timestamp": 1599328510057,
     "user": {
      "displayName": "Nelson LIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgrEZmWMjk_h9SZRyH_-oJW-4yrQ19ywOKCx8EA=s64",
      "userId": "03694478629413699942"
     },
     "user_tz": -480
    },
    "id": "jbuoJCYJ83Uk"
   },
   "outputs": [],
   "source": [
    "class MaskedSoftmax(Layer):\n",
    "    \"\"\"\n",
    "    在序列长度那一维进行softmax，并mask掉padding部分\n",
    "    \"\"\"\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = K.cast(mask, K.floatx())\n",
    "            mask = K.expand_dims(mask, 2)\n",
    "            inputs = inputs - (1.0 - mask) * 1e12\n",
    "        return K.softmax(inputs, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n2vYtLW683Um"
   },
   "source": [
    "# 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 72203,
     "status": "ok",
     "timestamp": 1599328584908,
     "user": {
      "displayName": "Nelson LIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgrEZmWMjk_h9SZRyH_-oJW-4yrQ19ywOKCx8EA=s64",
      "userId": "03694478629413699942"
     },
     "user_tz": -480
    },
    "id": "kNmeanl_83Um"
   },
   "outputs": [],
   "source": [
    "model = build_transformer_model(\n",
    "    config_path,\n",
    "    checkpoint_path,\n",
    ")\n",
    "\n",
    "output = Dense(2)(model.output)\n",
    "output = MaskedSoftmax()(output)\n",
    "output = Permute((2, 1))(output)\n",
    "\n",
    "model = Model(model.input, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1870,
     "status": "ok",
     "timestamp": 1599328592200,
     "user": {
      "displayName": "Nelson LIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgrEZmWMjk_h9SZRyH_-oJW-4yrQ19ywOKCx8EA=s64",
      "userId": "03694478629413699942"
     },
     "user_tz": -480
    },
    "id": "MLkZijDScTbM",
    "outputId": "477066a3-3b33-4b87-9ff4-5fd6d5cbe88f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input-Token (InputLayer)        [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Segment (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token (Embedding)     (None, None, 1024)   21635072    Input-Token[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Segment (Embedding)   (None, None, 1024)   2048        Input-Segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token-Segment (Add)   (None, None, 1024)   0           Embedding-Token[0][0]            \n",
      "                                                                 Embedding-Segment[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Position (PositionEmb (None, None, 1024)   524288      Embedding-Token-Segment[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Norm (LayerNormalizat (None, None, 1024)   2048        Embedding-Position[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Dropout (Dropout)     (None, None, 1024)   0           Embedding-Norm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 1024)   4198400     Embedding-Dropout[0][0]          \n",
      "                                                                 Embedding-Dropout[0][0]          \n",
      "                                                                 Embedding-Dropout[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 1024)   0           Embedding-Dropout[0][0]          \n",
      "                                                                 Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-MultiHeadSelfAtte (None, None, 1024)   2048        Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward (Feed (None, None, 1024)   8393728     Transformer-0-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward-Dropo (None, None, 1024)   0           Transformer-0-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward-Add ( (None, None, 1024)   0           Transformer-0-MultiHeadSelfAttent\n",
      "                                                                 Transformer-0-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-0-FeedForward-Norm  (None, None, 1024)   2048        Transformer-0-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 1024)   4198400     Transformer-0-FeedForward-Norm[0]\n",
      "                                                                 Transformer-0-FeedForward-Norm[0]\n",
      "                                                                 Transformer-0-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-0-FeedForward-Norm[0]\n",
      "                                                                 Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-MultiHeadSelfAtte (None, None, 1024)   2048        Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward (Feed (None, None, 1024)   8393728     Transformer-1-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward-Dropo (None, None, 1024)   0           Transformer-1-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward-Add ( (None, None, 1024)   0           Transformer-1-MultiHeadSelfAttent\n",
      "                                                                 Transformer-1-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-1-FeedForward-Norm  (None, None, 1024)   2048        Transformer-1-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 1024)   4198400     Transformer-1-FeedForward-Norm[0]\n",
      "                                                                 Transformer-1-FeedForward-Norm[0]\n",
      "                                                                 Transformer-1-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-1-FeedForward-Norm[0]\n",
      "                                                                 Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-MultiHeadSelfAtte (None, None, 1024)   2048        Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward (Feed (None, None, 1024)   8393728     Transformer-2-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward-Dropo (None, None, 1024)   0           Transformer-2-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward-Add ( (None, None, 1024)   0           Transformer-2-MultiHeadSelfAttent\n",
      "                                                                 Transformer-2-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-2-FeedForward-Norm  (None, None, 1024)   2048        Transformer-2-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 1024)   4198400     Transformer-2-FeedForward-Norm[0]\n",
      "                                                                 Transformer-2-FeedForward-Norm[0]\n",
      "                                                                 Transformer-2-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-2-FeedForward-Norm[0]\n",
      "                                                                 Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-MultiHeadSelfAtte (None, None, 1024)   2048        Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward (Feed (None, None, 1024)   8393728     Transformer-3-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward-Dropo (None, None, 1024)   0           Transformer-3-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward-Add ( (None, None, 1024)   0           Transformer-3-MultiHeadSelfAttent\n",
      "                                                                 Transformer-3-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-3-FeedForward-Norm  (None, None, 1024)   2048        Transformer-3-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-MultiHeadSelfAtte (None, None, 1024)   4198400     Transformer-3-FeedForward-Norm[0]\n",
      "                                                                 Transformer-3-FeedForward-Norm[0]\n",
      "                                                                 Transformer-3-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-4-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-3-FeedForward-Norm[0]\n",
      "                                                                 Transformer-4-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-MultiHeadSelfAtte (None, None, 1024)   2048        Transformer-4-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-FeedForward (Feed (None, None, 1024)   8393728     Transformer-4-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-FeedForward-Dropo (None, None, 1024)   0           Transformer-4-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-FeedForward-Add ( (None, None, 1024)   0           Transformer-4-MultiHeadSelfAttent\n",
      "                                                                 Transformer-4-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-4-FeedForward-Norm  (None, None, 1024)   2048        Transformer-4-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-MultiHeadSelfAtte (None, None, 1024)   4198400     Transformer-4-FeedForward-Norm[0]\n",
      "                                                                 Transformer-4-FeedForward-Norm[0]\n",
      "                                                                 Transformer-4-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-5-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-4-FeedForward-Norm[0]\n",
      "                                                                 Transformer-5-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-MultiHeadSelfAtte (None, None, 1024)   2048        Transformer-5-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-FeedForward (Feed (None, None, 1024)   8393728     Transformer-5-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-FeedForward-Dropo (None, None, 1024)   0           Transformer-5-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-FeedForward-Add ( (None, None, 1024)   0           Transformer-5-MultiHeadSelfAttent\n",
      "                                                                 Transformer-5-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-5-FeedForward-Norm  (None, None, 1024)   2048        Transformer-5-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-MultiHeadSelfAtte (None, None, 1024)   4198400     Transformer-5-FeedForward-Norm[0]\n",
      "                                                                 Transformer-5-FeedForward-Norm[0]\n",
      "                                                                 Transformer-5-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-6-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-5-FeedForward-Norm[0]\n",
      "                                                                 Transformer-6-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-MultiHeadSelfAtte (None, None, 1024)   2048        Transformer-6-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-FeedForward (Feed (None, None, 1024)   8393728     Transformer-6-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-FeedForward-Dropo (None, None, 1024)   0           Transformer-6-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-FeedForward-Add ( (None, None, 1024)   0           Transformer-6-MultiHeadSelfAttent\n",
      "                                                                 Transformer-6-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-6-FeedForward-Norm  (None, None, 1024)   2048        Transformer-6-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-MultiHeadSelfAtte (None, None, 1024)   4198400     Transformer-6-FeedForward-Norm[0]\n",
      "                                                                 Transformer-6-FeedForward-Norm[0]\n",
      "                                                                 Transformer-6-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-7-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-6-FeedForward-Norm[0]\n",
      "                                                                 Transformer-7-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-MultiHeadSelfAtte (None, None, 1024)   2048        Transformer-7-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-FeedForward (Feed (None, None, 1024)   8393728     Transformer-7-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-FeedForward-Dropo (None, None, 1024)   0           Transformer-7-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-FeedForward-Add ( (None, None, 1024)   0           Transformer-7-MultiHeadSelfAttent\n",
      "                                                                 Transformer-7-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-7-FeedForward-Norm  (None, None, 1024)   2048        Transformer-7-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-MultiHeadSelfAtte (None, None, 1024)   4198400     Transformer-7-FeedForward-Norm[0]\n",
      "                                                                 Transformer-7-FeedForward-Norm[0]\n",
      "                                                                 Transformer-7-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-8-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-7-FeedForward-Norm[0]\n",
      "                                                                 Transformer-8-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-MultiHeadSelfAtte (None, None, 1024)   2048        Transformer-8-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-FeedForward (Feed (None, None, 1024)   8393728     Transformer-8-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-FeedForward-Dropo (None, None, 1024)   0           Transformer-8-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-FeedForward-Add ( (None, None, 1024)   0           Transformer-8-MultiHeadSelfAttent\n",
      "                                                                 Transformer-8-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-8-FeedForward-Norm  (None, None, 1024)   2048        Transformer-8-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-MultiHeadSelfAtte (None, None, 1024)   4198400     Transformer-8-FeedForward-Norm[0]\n",
      "                                                                 Transformer-8-FeedForward-Norm[0]\n",
      "                                                                 Transformer-8-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-9-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-MultiHeadSelfAtte (None, None, 1024)   0           Transformer-8-FeedForward-Norm[0]\n",
      "                                                                 Transformer-9-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-MultiHeadSelfAtte (None, None, 1024)   2048        Transformer-9-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-FeedForward (Feed (None, None, 1024)   8393728     Transformer-9-MultiHeadSelfAttent\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-FeedForward-Dropo (None, None, 1024)   0           Transformer-9-FeedForward[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-FeedForward-Add ( (None, None, 1024)   0           Transformer-9-MultiHeadSelfAttent\n",
      "                                                                 Transformer-9-FeedForward-Dropout\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-9-FeedForward-Norm  (None, None, 1024)   2048        Transformer-9-FeedForward-Add[0][\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-9-FeedForward-Norm[0]\n",
      "                                                                 Transformer-9-FeedForward-Norm[0]\n",
      "                                                                 Transformer-9-FeedForward-Norm[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-10-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-9-FeedForward-Norm[0]\n",
      "                                                                 Transformer-10-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-10-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-FeedForward (Fee (None, None, 1024)   8393728     Transformer-10-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-FeedForward-Drop (None, None, 1024)   0           Transformer-10-FeedForward[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-FeedForward-Add  (None, None, 1024)   0           Transformer-10-MultiHeadSelfAtten\n",
      "                                                                 Transformer-10-FeedForward-Dropou\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-10-FeedForward-Norm (None, None, 1024)   2048        Transformer-10-FeedForward-Add[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-10-FeedForward-Norm[0\n",
      "                                                                 Transformer-10-FeedForward-Norm[0\n",
      "                                                                 Transformer-10-FeedForward-Norm[0\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-11-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-10-FeedForward-Norm[0\n",
      "                                                                 Transformer-11-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-11-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-FeedForward (Fee (None, None, 1024)   8393728     Transformer-11-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-FeedForward-Drop (None, None, 1024)   0           Transformer-11-FeedForward[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-FeedForward-Add  (None, None, 1024)   0           Transformer-11-MultiHeadSelfAtten\n",
      "                                                                 Transformer-11-FeedForward-Dropou\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-11-FeedForward-Norm (None, None, 1024)   2048        Transformer-11-FeedForward-Add[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-12-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-11-FeedForward-Norm[0\n",
      "                                                                 Transformer-11-FeedForward-Norm[0\n",
      "                                                                 Transformer-11-FeedForward-Norm[0\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-12-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-12-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-12-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-11-FeedForward-Norm[0\n",
      "                                                                 Transformer-12-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-12-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-12-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-12-FeedForward (Fee (None, None, 1024)   8393728     Transformer-12-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-12-FeedForward-Drop (None, None, 1024)   0           Transformer-12-FeedForward[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-12-FeedForward-Add  (None, None, 1024)   0           Transformer-12-MultiHeadSelfAtten\n",
      "                                                                 Transformer-12-FeedForward-Dropou\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-12-FeedForward-Norm (None, None, 1024)   2048        Transformer-12-FeedForward-Add[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-13-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-12-FeedForward-Norm[0\n",
      "                                                                 Transformer-12-FeedForward-Norm[0\n",
      "                                                                 Transformer-12-FeedForward-Norm[0\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-13-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-13-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-13-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-12-FeedForward-Norm[0\n",
      "                                                                 Transformer-13-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-13-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-13-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-13-FeedForward (Fee (None, None, 1024)   8393728     Transformer-13-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-13-FeedForward-Drop (None, None, 1024)   0           Transformer-13-FeedForward[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-13-FeedForward-Add  (None, None, 1024)   0           Transformer-13-MultiHeadSelfAtten\n",
      "                                                                 Transformer-13-FeedForward-Dropou\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-13-FeedForward-Norm (None, None, 1024)   2048        Transformer-13-FeedForward-Add[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-14-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-13-FeedForward-Norm[0\n",
      "                                                                 Transformer-13-FeedForward-Norm[0\n",
      "                                                                 Transformer-13-FeedForward-Norm[0\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-14-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-14-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-14-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-13-FeedForward-Norm[0\n",
      "                                                                 Transformer-14-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-14-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-14-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-14-FeedForward (Fee (None, None, 1024)   8393728     Transformer-14-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-14-FeedForward-Drop (None, None, 1024)   0           Transformer-14-FeedForward[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-14-FeedForward-Add  (None, None, 1024)   0           Transformer-14-MultiHeadSelfAtten\n",
      "                                                                 Transformer-14-FeedForward-Dropou\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-14-FeedForward-Norm (None, None, 1024)   2048        Transformer-14-FeedForward-Add[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-15-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-14-FeedForward-Norm[0\n",
      "                                                                 Transformer-14-FeedForward-Norm[0\n",
      "                                                                 Transformer-14-FeedForward-Norm[0\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-15-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-15-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-15-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-14-FeedForward-Norm[0\n",
      "                                                                 Transformer-15-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-15-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-15-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-15-FeedForward (Fee (None, None, 1024)   8393728     Transformer-15-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-15-FeedForward-Drop (None, None, 1024)   0           Transformer-15-FeedForward[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-15-FeedForward-Add  (None, None, 1024)   0           Transformer-15-MultiHeadSelfAtten\n",
      "                                                                 Transformer-15-FeedForward-Dropou\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-15-FeedForward-Norm (None, None, 1024)   2048        Transformer-15-FeedForward-Add[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-16-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-15-FeedForward-Norm[0\n",
      "                                                                 Transformer-15-FeedForward-Norm[0\n",
      "                                                                 Transformer-15-FeedForward-Norm[0\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-16-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-16-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-16-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-15-FeedForward-Norm[0\n",
      "                                                                 Transformer-16-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-16-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-16-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-16-FeedForward (Fee (None, None, 1024)   8393728     Transformer-16-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-16-FeedForward-Drop (None, None, 1024)   0           Transformer-16-FeedForward[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-16-FeedForward-Add  (None, None, 1024)   0           Transformer-16-MultiHeadSelfAtten\n",
      "                                                                 Transformer-16-FeedForward-Dropou\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-16-FeedForward-Norm (None, None, 1024)   2048        Transformer-16-FeedForward-Add[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-17-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-16-FeedForward-Norm[0\n",
      "                                                                 Transformer-16-FeedForward-Norm[0\n",
      "                                                                 Transformer-16-FeedForward-Norm[0\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-17-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-17-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-17-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-16-FeedForward-Norm[0\n",
      "                                                                 Transformer-17-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-17-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-17-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-17-FeedForward (Fee (None, None, 1024)   8393728     Transformer-17-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-17-FeedForward-Drop (None, None, 1024)   0           Transformer-17-FeedForward[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-17-FeedForward-Add  (None, None, 1024)   0           Transformer-17-MultiHeadSelfAtten\n",
      "                                                                 Transformer-17-FeedForward-Dropou\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-17-FeedForward-Norm (None, None, 1024)   2048        Transformer-17-FeedForward-Add[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-18-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-17-FeedForward-Norm[0\n",
      "                                                                 Transformer-17-FeedForward-Norm[0\n",
      "                                                                 Transformer-17-FeedForward-Norm[0\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-18-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-18-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-18-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-17-FeedForward-Norm[0\n",
      "                                                                 Transformer-18-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-18-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-18-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-18-FeedForward (Fee (None, None, 1024)   8393728     Transformer-18-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-18-FeedForward-Drop (None, None, 1024)   0           Transformer-18-FeedForward[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-18-FeedForward-Add  (None, None, 1024)   0           Transformer-18-MultiHeadSelfAtten\n",
      "                                                                 Transformer-18-FeedForward-Dropou\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-18-FeedForward-Norm (None, None, 1024)   2048        Transformer-18-FeedForward-Add[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-19-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-18-FeedForward-Norm[0\n",
      "                                                                 Transformer-18-FeedForward-Norm[0\n",
      "                                                                 Transformer-18-FeedForward-Norm[0\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-19-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-19-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-19-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-18-FeedForward-Norm[0\n",
      "                                                                 Transformer-19-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-19-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-19-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-19-FeedForward (Fee (None, None, 1024)   8393728     Transformer-19-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-19-FeedForward-Drop (None, None, 1024)   0           Transformer-19-FeedForward[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-19-FeedForward-Add  (None, None, 1024)   0           Transformer-19-MultiHeadSelfAtten\n",
      "                                                                 Transformer-19-FeedForward-Dropou\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-19-FeedForward-Norm (None, None, 1024)   2048        Transformer-19-FeedForward-Add[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-20-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-19-FeedForward-Norm[0\n",
      "                                                                 Transformer-19-FeedForward-Norm[0\n",
      "                                                                 Transformer-19-FeedForward-Norm[0\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-20-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-20-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-20-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-19-FeedForward-Norm[0\n",
      "                                                                 Transformer-20-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-20-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-20-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-20-FeedForward (Fee (None, None, 1024)   8393728     Transformer-20-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-20-FeedForward-Drop (None, None, 1024)   0           Transformer-20-FeedForward[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-20-FeedForward-Add  (None, None, 1024)   0           Transformer-20-MultiHeadSelfAtten\n",
      "                                                                 Transformer-20-FeedForward-Dropou\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-20-FeedForward-Norm (None, None, 1024)   2048        Transformer-20-FeedForward-Add[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-21-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-20-FeedForward-Norm[0\n",
      "                                                                 Transformer-20-FeedForward-Norm[0\n",
      "                                                                 Transformer-20-FeedForward-Norm[0\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-21-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-21-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-21-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-20-FeedForward-Norm[0\n",
      "                                                                 Transformer-21-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-21-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-21-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-21-FeedForward (Fee (None, None, 1024)   8393728     Transformer-21-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-21-FeedForward-Drop (None, None, 1024)   0           Transformer-21-FeedForward[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-21-FeedForward-Add  (None, None, 1024)   0           Transformer-21-MultiHeadSelfAtten\n",
      "                                                                 Transformer-21-FeedForward-Dropou\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-21-FeedForward-Norm (None, None, 1024)   2048        Transformer-21-FeedForward-Add[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-22-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-21-FeedForward-Norm[0\n",
      "                                                                 Transformer-21-FeedForward-Norm[0\n",
      "                                                                 Transformer-21-FeedForward-Norm[0\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-22-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-22-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-22-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-21-FeedForward-Norm[0\n",
      "                                                                 Transformer-22-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-22-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-22-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-22-FeedForward (Fee (None, None, 1024)   8393728     Transformer-22-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-22-FeedForward-Drop (None, None, 1024)   0           Transformer-22-FeedForward[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-22-FeedForward-Add  (None, None, 1024)   0           Transformer-22-MultiHeadSelfAtten\n",
      "                                                                 Transformer-22-FeedForward-Dropou\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-22-FeedForward-Norm (None, None, 1024)   2048        Transformer-22-FeedForward-Add[0]\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-23-MultiHeadSelfAtt (None, None, 1024)   4198400     Transformer-22-FeedForward-Norm[0\n",
      "                                                                 Transformer-22-FeedForward-Norm[0\n",
      "                                                                 Transformer-22-FeedForward-Norm[0\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-23-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-23-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-23-MultiHeadSelfAtt (None, None, 1024)   0           Transformer-22-FeedForward-Norm[0\n",
      "                                                                 Transformer-23-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-23-MultiHeadSelfAtt (None, None, 1024)   2048        Transformer-23-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-23-FeedForward (Fee (None, None, 1024)   8393728     Transformer-23-MultiHeadSelfAtten\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-23-FeedForward-Drop (None, None, 1024)   0           Transformer-23-FeedForward[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Transformer-23-FeedForward-Add  (None, None, 1024)   0           Transformer-23-MultiHeadSelfAtten\n",
      "                                                                 Transformer-23-FeedForward-Dropou\n",
      "__________________________________________________________________________________________________\n",
      "Transformer-23-FeedForward-Norm (None, None, 1024)   2048        Transformer-23-FeedForward-Add[0]\n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 2)      2050        Transformer-23-FeedForward-Norm[0\n",
      "__________________________________________________________________________________________________\n",
      "masked_softmax (MaskedSoftmax)  (None, None, 2)      0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "permute (Permute)               (None, 2, None)      0           masked_softmax[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 324,474,882\n",
      "Trainable params: 324,474,882\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TTDznSI483Uo"
   },
   "source": [
    "# 评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1198,
     "status": "ok",
     "timestamp": 1599328596639,
     "user": {
      "displayName": "Nelson LIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgrEZmWMjk_h9SZRyH_-oJW-4yrQ19ywOKCx8EA=s64",
      "userId": "03694478629413699942"
     },
     "user_tz": -480
    },
    "id": "aBwxu8Lw83Up"
   },
   "outputs": [],
   "source": [
    "def sparse_categorical_crossentropy(y_true, y_pred):\n",
    "    # y_true需要重新明确一下shape和dtype\n",
    "    y_true = K.reshape(y_true, K.shape(y_pred)[:-1])\n",
    "    y_true = K.cast(y_true, 'int32')\n",
    "    y_true = K.one_hot(y_true, K.shape(y_pred)[2])\n",
    "    # 计算交叉熵\n",
    "    return K.mean(K.categorical_crossentropy(y_true, y_pred))\n",
    "\n",
    "\n",
    "def sparse_accuracy(y_true, y_pred):\n",
    "    # y_true需要重新明确一下shape和dtype\n",
    "    y_true = K.reshape(y_true, K.shape(y_pred)[:-1])\n",
    "    y_true = K.cast(y_true, 'int32')\n",
    "    # 计算准确率\n",
    "    y_pred = K.cast(K.argmax(y_pred, axis=2), 'int32')\n",
    "    return K.mean(K.cast(K.equal(y_true, y_pred), K.floatx()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cFxg5d8T83Uq"
   },
   "source": [
    "# 编译模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 545,
     "status": "ok",
     "timestamp": 1599328599127,
     "user": {
      "displayName": "Nelson LIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgrEZmWMjk_h9SZRyH_-oJW-4yrQ19ywOKCx8EA=s64",
      "userId": "03694478629413699942"
     },
     "user_tz": -480
    },
    "id": "T-r4oWgd83Ur"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=sparse_categorical_crossentropy,\n",
    "    optimizer=Adam(learing_rate),\n",
    "    metrics=[sparse_accuracy]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FCbOxQOM83Uu"
   },
   "source": [
    "# 答案抽取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 579,
     "status": "ok",
     "timestamp": 1599328602168,
     "user": {
      "displayName": "Nelson LIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgrEZmWMjk_h9SZRyH_-oJW-4yrQ19ywOKCx8EA=s64",
      "userId": "03694478629413699942"
     },
     "user_tz": -480
    },
    "id": "kSj4Ri9p83Uu"
   },
   "outputs": [],
   "source": [
    "def extract_answer(question, context, max_a_len=16):\n",
    "    \"\"\"\n",
    "    抽取答案函数\n",
    "    \"\"\"\n",
    "    max_q_len = 64\n",
    "    q_token_ids = tokenizer.encode(question, max_length=max_q_len)[0]\n",
    "    c_token_ids = tokenizer.encode(\n",
    "        context, max_length=maxlen - len(q_token_ids) + 1\n",
    "    )[0]\n",
    "    token_ids = q_token_ids + c_token_ids[1:]\n",
    "    segment_ids = [0] * len(q_token_ids) + [1] * (len(c_token_ids) - 1)\n",
    "    c_tokens = tokenizer.tokenize(context)[1:-1]\n",
    "    mapping = tokenizer.rematch(context, c_tokens)\n",
    "    probas = model.predict([np.array([token_ids]), np.array([segment_ids])])[0]\n",
    "    probas = probas[:, len(q_token_ids):-1]\n",
    "    start_end, score = None, -1\n",
    "    for start, p_start in enumerate(probas[0]):\n",
    "        for end, p_end in enumerate(probas[1]):\n",
    "            if end >= start and end < start + max_a_len:\n",
    "                if p_start * p_end > score:\n",
    "                    start_end = (start, end)\n",
    "                    score = p_start * p_end\n",
    "    start, end = start_end\n",
    "    return context[mapping[start][0]:mapping[end][-1] + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UPJHj4nS83Uw"
   },
   "source": [
    "# 预测文件生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 608,
     "status": "ok",
     "timestamp": 1599328609397,
     "user": {
      "displayName": "Nelson LIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgrEZmWMjk_h9SZRyH_-oJW-4yrQ19ywOKCx8EA=s64",
      "userId": "03694478629413699942"
     },
     "user_tz": -480
    },
    "id": "1yBZNbHu83Uw"
   },
   "outputs": [],
   "source": [
    "def predict_to_file(infile, out_file):\n",
    "    \"\"\"预测结果到文件，方便提交\n",
    "    \"\"\"\n",
    "    fw = open(out_file, 'w', encoding='utf-8')\n",
    "    R = {}\n",
    "    for d in tqdm(load_data(infile)):\n",
    "        a = extract_answer(d[2], d[1])\n",
    "        R[d[0]] = a\n",
    "    R = json.dumps(R, ensure_ascii=False, indent=4)\n",
    "    fw.write(R)\n",
    "    fw.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4ceYNdp83Uz"
   },
   "source": [
    "# 官方评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 825,
     "status": "ok",
     "timestamp": 1599328692910,
     "user": {
      "displayName": "Nelson LIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgrEZmWMjk_h9SZRyH_-oJW-4yrQ19ywOKCx8EA=s64",
      "userId": "03694478629413699942"
     },
     "user_tz": -480
    },
    "id": "DkKAIfoTe6hN"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import io\n",
    "import json\n",
    "sys.path.append(data_dir)\n",
    "from evluation_utils import evaluate as src_evaluate\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 612,
     "status": "ok",
     "timestamp": 1599328741331,
     "user": {
      "displayName": "Nelson LIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgrEZmWMjk_h9SZRyH_-oJW-4yrQ19ywOKCx8EA=s64",
      "userId": "03694478629413699942"
     },
     "user_tz": -480
    },
    "id": "8Naz8qZIVepQ"
   },
   "outputs": [],
   "source": [
    "file_name_ref_ans = os.path.join(data_dir,'demo/demo_dev.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 856,
     "status": "ok",
     "timestamp": 1599328934182,
     "user": {
      "displayName": "Nelson LIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgrEZmWMjk_h9SZRyH_-oJW-4yrQ19ywOKCx8EA=s64",
      "userId": "03694478629413699942"
     },
     "user_tz": -480
    },
    "id": "6x2t3trWbojv"
   },
   "outputs": [],
   "source": [
    "dev_data = load_data(file_name_ref_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 566,
     "status": "ok",
     "timestamp": 1599328941903,
     "user": {
      "displayName": "Nelson LIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgrEZmWMjk_h9SZRyH_-oJW-4yrQ19ywOKCx8EA=s64",
      "userId": "03694478629413699942"
     },
     "user_tz": -480
    },
    "id": "R36ZMm7YbtxQ",
    "outputId": "ac0c49aa-882a-4662-f550-5c5c53bd43a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 602,
     "status": "ok",
     "timestamp": 1599328826322,
     "user": {
      "displayName": "Nelson LIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgrEZmWMjk_h9SZRyH_-oJW-4yrQ19ywOKCx8EA=s64",
      "userId": "03694478629413699942"
     },
     "user_tz": -480
    },
    "id": "GAOe0dUWVptc"
   },
   "outputs": [],
   "source": [
    "file_name_pred_ans = os.path.join(data_dir,'demo/demo_dev.json').replace('.json','') + '_pred.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 639,
     "status": "ok",
     "timestamp": 1599328827460,
     "user": {
      "displayName": "Nelson LIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgrEZmWMjk_h9SZRyH_-oJW-4yrQ19ywOKCx8EA=s64",
      "userId": "03694478629413699942"
     },
     "user_tz": -480
    },
    "id": "xhJrmMKzbHT-",
    "outputId": "fe1965e1-baf3-47e8-cce8-5273f7b97c54"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/drive/My Drive/Colab Notebooks/Machine Reading Comprehension/data/demo/demo_dev_pred.json'"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name_pred_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 600,
     "status": "ok",
     "timestamp": 1599331065026,
     "user": {
      "displayName": "Nelson LIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgrEZmWMjk_h9SZRyH_-oJW-4yrQ19ywOKCx8EA=s64",
      "userId": "03694478629413699942"
     },
     "user_tz": -480
    },
    "id": "wNrSRL0i83Uz"
   },
   "outputs": [],
   "source": [
    "def evaluate(file_name_ref_ans,file_name_pred_ans):\n",
    "    \"\"\"\n",
    "    评测函数（官方提供评测脚本evaluate.py）\n",
    "    \"\"\"\n",
    "    predict_to_file(file_name_ref_ans,file_name_pred_ans)\n",
    "    ref_ans = json.load(io.open(file_name_ref_ans))\n",
    "    pred_ans = json.load(io.open(file_name_pred_ans))\n",
    "    F1, EM, TOTAL, SKIP = src_evaluate(ref_ans, pred_ans)\n",
    "    output_result = OrderedDict()\n",
    "    output_result['F1'] = '%.3f' % F1\n",
    "    output_result['EM'] = '%.3f' % EM\n",
    "    output_result['TOTAL'] = TOTAL\n",
    "    output_result['SKIP'] = SKIP\n",
    "    return output_result\n",
    "\n",
    "\n",
    "class Evaluator(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    评估和保存模型\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.best_val_f1 = 0.\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        metrics = evaluate(file_name_ref_ans,file_name_pred_ans)\n",
    "        if float(metrics['F1']) >= self.best_val_f1:\n",
    "            self.best_val_f1 = float(metrics['F1'])\n",
    "            model.save_weights(os.path.join(output_dir,'roberta_best_model.weights'))\n",
    "            model.save(os.path.join(output_dir,'roberta_best_model.h5'))\n",
    "        metrics['BEST_F1'] = self.best_val_f1\n",
    "        print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rivf9wn883U1"
   },
   "source": [
    "# 获取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 777,
     "status": "ok",
     "timestamp": 1599331076278,
     "user": {
      "displayName": "Nelson LIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgrEZmWMjk_h9SZRyH_-oJW-4yrQ19ywOKCx8EA=s64",
      "userId": "03694478629413699942"
     },
     "user_tz": -480
    },
    "id": "z_cSRxhH83U2"
   },
   "outputs": [],
   "source": [
    "train_generator = data_generator(train_data, batch_size)\n",
    "evaluator = Evaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 492,
     "status": "ok",
     "timestamp": 1599331076280,
     "user": {
      "displayName": "Nelson LIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgrEZmWMjk_h9SZRyH_-oJW-4yrQ19ywOKCx8EA=s64",
      "userId": "03694478629413699942"
     },
     "user_tz": -480
    },
    "id": "sTwKPrhXKBL0"
   },
   "outputs": [],
   "source": [
    "[batch_token_ids, batch_segment_ids], batch_labels = next(iter(train_generator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kJi3sNmT83U4"
   },
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2253512,
     "status": "ok",
     "timestamp": 1599333331485,
     "user": {
      "displayName": "Nelson LIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgrEZmWMjk_h9SZRyH_-oJW-4yrQ19ywOKCx8EA=s64",
      "userId": "03694478629413699942"
     },
     "user_tz": -480
    },
    "id": "VlHXytC583U4",
    "outputId": "d921eb96-e6c6-40a8-977b-ffce449b7930",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 1.0154 - sparse_accuracy: 0.8000  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [05:57<00:00,  3.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('F1', '53.141'), ('EM', '39.000'), ('TOTAL', 100), ('SKIP', 0), ('BEST_F1', 53.141)])\n",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "25/25 [==============================] - 2198s 88s/step - loss: 1.0154 - sparse_accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1d70ecf780>"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs=1\n",
    "model.fit_generator(\n",
    "    train_generator.forfit(),\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=epochs,\n",
    "    callbacks=[evaluator]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RjVWAQBF83U6"
   },
   "source": [
    "# 加载最优模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 95094,
     "status": "ok",
     "timestamp": 1590118771109,
     "user": {
      "displayName": "罗杰",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg-a_YBdWbEZ2-QLI4_OGvTo7Epwx70DhGLvFws=s64",
      "userId": "01455695120655509307"
     },
     "user_tz": -480
    },
    "id": "N9nOPUziNhBT",
    "outputId": "d84e6462-2911-4af7-ffa4-2a8a97f4d335"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "100%|██████████| 1417/1417 [00:46<00:00, 30.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('F1', '74.491'), ('EM', '63.232'), ('TOTAL', 1417), ('SKIP', 0)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model=load_model(os.path.join(output_dir,'roberta_best_model.h5'),custom_objects={'MaskedSoftmax':MaskedSoftmax,'sparse_accuracy':sparse_accuracy})\n",
    "print(evaluate(os.path.join(data_dir,'dev.json')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JnOzk_2X3tuA"
   },
   "source": [
    "# 样例文章问题答案预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 569,
     "status": "ok",
     "timestamp": 1599336633034,
     "user": {
      "displayName": "Nelson LIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgrEZmWMjk_h9SZRyH_-oJW-4yrQ19ywOKCx8EA=s64",
      "userId": "03694478629413699942"
     },
     "user_tz": -480
    },
    "id": "mUcBeI1xbVJd"
   },
   "outputs": [],
   "source": [
    "test_data = dev_data[89]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1035,
     "status": "ok",
     "timestamp": 1599336634618,
     "user": {
      "displayName": "Nelson LIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgrEZmWMjk_h9SZRyH_-oJW-4yrQ19ywOKCx8EA=s64",
      "userId": "03694478629413699942"
     },
     "user_tz": -480
    },
    "id": "sbXCbIPhFYkr"
   },
   "outputs": [],
   "source": [
    "context = test_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1035,
     "status": "ok",
     "timestamp": 1599336634853,
     "user": {
      "displayName": "Nelson LIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgrEZmWMjk_h9SZRyH_-oJW-4yrQ19ywOKCx8EA=s64",
      "userId": "03694478629413699942"
     },
     "user_tz": -480
    },
    "id": "GMajUvq0Neiq"
   },
   "outputs": [],
   "source": [
    "question = test_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 850,
     "status": "ok",
     "timestamp": 1599336635098,
     "user": {
      "displayName": "Nelson LIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgrEZmWMjk_h9SZRyH_-oJW-4yrQ19ywOKCx8EA=s64",
      "userId": "03694478629413699942"
     },
     "user_tz": -480
    },
    "id": "78eyIPI5Nfwv"
   },
   "outputs": [],
   "source": [
    "real_answer = test_data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3860,
     "status": "ok",
     "timestamp": 1599336638264,
     "user": {
      "displayName": "Nelson LIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgrEZmWMjk_h9SZRyH_-oJW-4yrQ19ywOKCx8EA=s64",
      "userId": "03694478629413699942"
     },
     "user_tz": -480
    },
    "id": "FRN8S5a14DPD"
   },
   "outputs": [],
   "source": [
    "pred_answer = extract_answer(question,context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3745,
     "status": "ok",
     "timestamp": 1599336638267,
     "user": {
      "displayName": "Nelson LIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgrEZmWMjk_h9SZRyH_-oJW-4yrQ19ywOKCx8EA=s64",
      "userId": "03694478629413699942"
     },
     "user_tz": -480
    },
    "id": "NwPa5OZH4EiC",
    "outputId": "a98b63ca-a40b-43a0-b1a3-fbb9342b114c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'一般纳税人开具普通发票与开具增值税专用发票,不管是开给的是小规模纳税人还是一般纳税人,都是按17%计算交税的。|一般纳税人是指年应征增值税销售额(以下简称年应税销售额,包括一个公历年度内的全部应税销售额)超过财政部规定的小规模纳税人标准的企业和企业性单位。一般纳税人的特点是增值税进项税额可以抵扣销项税额。|会计从业 税务办税指南会计从业 税务知识科普会计从业 税票知识科普会计从业 税务行业问答会计从业 税务发票查询会计从业 税务网上申报'"
      ]
     },
     "execution_count": 118,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 575,
     "status": "ok",
     "timestamp": 1599336639696,
     "user": {
      "displayName": "Nelson LIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgrEZmWMjk_h9SZRyH_-oJW-4yrQ19ywOKCx8EA=s64",
      "userId": "03694478629413699942"
     },
     "user_tz": -480
    },
    "id": "HI5n7FYW4FzL",
    "outputId": "cb4a1922-3741-49d6-9909-fcfde09db03d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'普通发票税点是多少'"
      ]
     },
     "execution_count": 119,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 564,
     "status": "ok",
     "timestamp": 1599336641089,
     "user": {
      "displayName": "Nelson LIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgrEZmWMjk_h9SZRyH_-oJW-4yrQ19ywOKCx8EA=s64",
      "userId": "03694478629413699942"
     },
     "user_tz": -480
    },
    "id": "ujEE6cXh4G31",
    "outputId": "427d9344-c79d-4d29-e303-ddde8458c2d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['17%']"
      ]
     },
     "execution_count": 120,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 381,
     "status": "ok",
     "timestamp": 1599336642101,
     "user": {
      "displayName": "Nelson LIN",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgrEZmWMjk_h9SZRyH_-oJW-4yrQ19ywOKCx8EA=s64",
      "userId": "03694478629413699942"
     },
     "user_tz": -480
    },
    "id": "OJ_afp324Imi",
    "outputId": "d7e01389-3f0c-4a6f-e217-17b3f5e8bd13"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'17%'"
      ]
     },
     "execution_count": 121,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gGjQ9Z9A4KLy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Machine Reading Comprehension.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
