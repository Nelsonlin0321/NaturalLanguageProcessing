{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c6Pbz2Cn2Azb"
   },
   "source": [
    "#  Tutorial of Seq2seq with Attentions and Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P2oEPwEz2Azc"
   },
   "source": [
    "### 1) Read Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LK-p19GY2Azd"
   },
   "source": [
    "reference : https://www.tensorflow.org/tutorials/text/nmt_with_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cSXIGogG2Aze",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import io\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9fa6ziAP2Onk",
    "outputId": "bc6ba1a2-8bd9-4651-844a-2fe0256fd310"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.4.0\n"
     ]
    }
   ],
   "source": [
    "# %tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow version \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I5YL90J_2Azj"
   },
   "outputs": [],
   "source": [
    "path_to_zip = tf.keras.utils.get_file(\n",
    "    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
    "    extract=True)\n",
    "\n",
    "path_to_file = os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BN_yI6AA2Azl"
   },
   "source": [
    "### 2) Text PreProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b742aPAH2Azm"
   },
   "source": [
    "#### (1) Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RpVq3d0T2Azm"
   },
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o7xiir9S2Azr"
   },
   "outputs": [],
   "source": [
    "def preprocess_sentence(w,isTarget=False):\n",
    "    w = unicode_to_ascii(w.lower().strip())\n",
    "\n",
    "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "    w = re.sub(r'[\" \"]+', \" \", w)\n",
    "\n",
    "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "\n",
    "    w = w.strip()\n",
    "\n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    if isTarget:\n",
    "        w =  w + ' <end>'\n",
    "    else:\n",
    "        w = '<start> ' + w + ' <end>'\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "26me8Hgi2Azx",
    "outputId": "9ff05671-08bc-4aca-8ba7-ab92aef821ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "may i borrow this book ? <end>\n",
      "b'<start> \\xc2\\xbf puedo tomar prestado este libro ? <end>'\n"
     ]
    }
   ],
   "source": [
    "en_sentence = u\"May I borrow this book?\"\n",
    "sp_sentence = u\"¿Puedo tomar prestado este libro?\"\n",
    "print(preprocess_sentence(en_sentence,True))\n",
    "print(preprocess_sentence(sp_sentence).encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j1a6neNR2Az0"
   },
   "outputs": [],
   "source": [
    "def create_dataset(path, num_examples):\n",
    "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')[:-1]\n",
    "\n",
    "    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\n",
    "\n",
    "    return zip(*word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PFPryfeZ2Az4"
   },
   "outputs": [],
   "source": [
    "en, sp = create_dataset(path_to_file, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pPg1Qrne0wKW",
    "outputId": "4c43c129-7a3d-4e61-f962-5c200fd5b01a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118963"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KtJQX7WZ2Az6",
    "outputId": "b3a8dd38-fbbe-40ee-925d-ba17dd852a16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> tadpoles become frogs . <end>\n",
      "<start> los renacuajos se convierten en ranas . <end>\n"
     ]
    }
   ],
   "source": [
    "print(en[29000])\n",
    "print(sp[29000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N4zvPgrM2Az9"
   },
   "source": [
    "#### (2) sentence tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XTN-mQmz2Az-"
   },
   "outputs": [],
   "source": [
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)\n",
    "\n",
    "def tokenize(lang):\n",
    "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    \n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "    \n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,padding='post')\n",
    "    \n",
    "    return tensor, lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gif9elXh2A0B"
   },
   "outputs": [],
   "source": [
    "def load_dataset(path, num_examples=None):\n",
    "\n",
    "    targ_lang, inp_lang = create_dataset(path, num_examples)\n",
    "\n",
    "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
    "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
    "\n",
    "    return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6WrrJOYT2A0D"
   },
   "outputs": [],
   "source": [
    "num_examples = 50000\n",
    "input_tensor, output_tensor, input_tokenizer, output_tokenizer = load_dataset(path_to_file, num_examples)\n",
    "max_length_targ, max_length_inp = max_length(output_tensor), max_length(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BP4e_K1l2A0F"
   },
   "outputs": [],
   "source": [
    "max_length_output, max_length_input = max_length(output_tensor), max_length(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PaD0o1Ls2A0I",
    "outputId": "4c784b29-d152-4e03-b5e0-107ec9e421be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000 40000 10000 10000\n"
     ]
    }
   ],
   "source": [
    "input_tensor_train, input_tensor_val, output_tensor_train, output_tensor_val = train_test_split(input_tensor, output_tensor, test_size=0.2)\n",
    "print(len(input_tensor_train), len(output_tensor_train), len(input_tensor_val), len(output_tensor_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EDEPJQVe2A0P"
   },
   "outputs": [],
   "source": [
    "def convert(lang, tensor):\n",
    "    for t in tensor:\n",
    "        if t!=0:\n",
    "            print (\"%d ----> %s\" % (t, lang.index_word[t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T-44O3bS2A0Y",
    "outputId": "3330dda6-ab8a-4793-e083-373eef524168"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "15 ----> me\n",
      "291 ----> gustaria\n",
      "1560 ----> besar\n",
      "10 ----> a\n",
      "43 ----> mary\n",
      "3 ----> .\n",
      "2 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "4 ----> i\n",
      "135 ----> d\n",
      "34 ----> like\n",
      "10 ----> to\n",
      "576 ----> kiss\n",
      "48 ----> mary\n",
      "3 ----> .\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "print (\"Input Language; index to word mapping\")\n",
    "convert(input_tokenizer, input_tensor_train[100])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(output_tokenizer, output_tensor_train[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0YO0JD32A0c"
   },
   "source": [
    "#### (3) DataSet Creating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DygkmbLR2A0d"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g2vOusyY2A0g"
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, output_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YmXDC10w2A0j",
    "outputId": "0edd2314-c0f3-4d48-e157-c323f218e5ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 16]), TensorShape([64, 12]))"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wkv91Nu12A0l",
    "outputId": "9fceab21-510b-41cc-b842-2f72fbfb0877"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 16])"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7ZKn1UA2A0x"
   },
   "source": [
    "### 2) Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wBgOESmj2A0y"
   },
   "source": [
    "##### 1) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RfgLjbma2A0y"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qpe9-8qv2A06"
   },
   "source": [
    "##### 2) parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qFAMy8RU2A08"
   },
   "outputs": [],
   "source": [
    "INPUT_VOCAB_SIZE = len(input_tokenizer.word_index)+1\n",
    "ENCODER_EMBEDDING_SIZE = 256\n",
    "ENCODER_UNITS = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EVBrE-nY2A1D"
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(INPUT_VOCAB_SIZE,ENCODER_EMBEDDING_SIZE,ENCODER_UNITS,BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "npqGDj0hidmk",
    "outputId": "c14c2755-a6d1-4e6e-e5b3-75199f44d7c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 16, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "byAv1AVE2A1K"
   },
   "source": [
    "### 3) Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57ejylqzidml"
   },
   "source": [
    "##### 1) DotProduct Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_IKV5z8eidml"
   },
   "source": [
    "![](./DotProductAttention.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A-EFBq9jidml"
   },
   "outputs": [],
   "source": [
    "class DotProductAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self,units):\n",
    "        super(DotProductAttention,self).__init__()\n",
    "        self.units = units\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        \n",
    "    def call(self,hidden,encode_output):\n",
    "        # query\n",
    "        attention_query = self.W1(encode_output)\n",
    "        \n",
    "        # key\n",
    "        attention_key = self.W2(hidden) \n",
    "        attention_key  = tf.expand_dims(attention_key ,axis = 1)\n",
    "        \n",
    "        # attention mechanism\n",
    "        matmul_qk = tf.matmul(attention_query, attention_key, transpose_b=True)\n",
    "        matmul_qk = tf.nn.tanh(matmul_qk)\n",
    "        attention_weights = tf.nn.softmax(matmul_qk, axis=1)\n",
    "        \n",
    "        # attention dotproduct\n",
    "        attention_values = encode_output\n",
    "        context_vector = attention_weights * attention_values\n",
    "        \n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnCDfACmidmm"
   },
   "source": [
    "![](./BahdanauAttention.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L2t0KVoxidmm"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # query hidden state shape == (batch_size, hidden size)\n",
    "        # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # values shape == (batch_size, max_len, hidden size)\n",
    "        # we are doing this to broadcast addition along the time axis to calculate the score\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cA7LHUIzidmn"
   },
   "outputs": [],
   "source": [
    "ATTENTIION_UNITS = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eGubvN45idmn"
   },
   "outputs": [],
   "source": [
    "attentionLayer = DotProductAttention(ATTENTIION_UNITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lO_0R9Q5idmn"
   },
   "outputs": [],
   "source": [
    "attention_result, attention_weights = attentionLayer(sample_hidden,sample_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UZEmIDnOidmo",
    "outputId": "59f813dd-5683-4a6c-9518-9912b2f38ae6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kpNKgrymidmo"
   },
   "outputs": [],
   "source": [
    "attentionLayer = BahdanauAttention(ATTENTIION_UNITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NOUIEBgZidmo"
   },
   "outputs": [],
   "source": [
    "attention_result, attention_weights = attentionLayer(sample_hidden,sample_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3BHGq6DTidmo",
    "outputId": "91cc10e2-bf99-4a01-8c84-aec67c95deb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention result shape: (batch size, units) (64, 1024)\n",
      "Attention weights shape: (batch_size, sequence_length, 1) (64, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
    "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jTMO9Bx32A1L"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz,attention_name):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,return_sequences=True,return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        if attention_name ==\"dotproduct\":\n",
    "            self.attentionLayer = DotProductAttention(self.dec_units)\n",
    "        elif attention_name == \"Bahdanau\":\n",
    "            self.attentionLayer = BahdanauAttention(self.dec_units)\n",
    "        else:\n",
    "            raise ValueError(\"Unkown Attention Mechanism\")\n",
    "                \n",
    "\n",
    "    def call(self,x,hidden,enc_output):\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        context_vector, attention_weights = self.attentionLayer(hidden,enc_output)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        output, state = self.gru(x)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        x = self.fc(output)\n",
    "        return x, state,attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jzy1q9CE2A1N"
   },
   "source": [
    "##### 2) Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uQum_rpv2A1O"
   },
   "outputs": [],
   "source": [
    "### parameter\n",
    "OUTPUT_VOCAB_SIZE = len(output_tokenizer.word_index)+1\n",
    "DECODER_UNITS = ENCODER_UNITS\n",
    "ENCODE_EMBEDDING_DIM = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ys4Uwz7y2A1V"
   },
   "outputs": [],
   "source": [
    "decoder = Decoder(OUTPUT_VOCAB_SIZE,ENCODE_EMBEDDING_DIM,DECODER_UNITS,BATCH_SIZE,\"dotproduct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GD-muECjidmq",
    "outputId": "9655ade3-64f3-4307-d33f-5abe45c50826"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 6817)\n"
     ]
    }
   ],
   "source": [
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((64, 1)),sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z9-PwxrZidmq"
   },
   "outputs": [],
   "source": [
    "decoder = Decoder(OUTPUT_VOCAB_SIZE,ENCODE_EMBEDDING_DIM,DECODER_UNITS,BATCH_SIZE,\"Bahdanau\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Yy_SDstidmq",
    "outputId": "fb782c08-26ae-4671-dacf-02c5d5486f2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 6817)\n"
     ]
    }
   ],
   "source": [
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((64, 1)),sample_hidden, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pqbg5o72A1l"
   },
   "source": [
    "### 4) Define Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cd9-JcTy2A1l"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hadERmRS2A1n"
   },
   "source": [
    "### 5)Seq2Seq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aWP8RjBXidmr"
   },
   "outputs": [],
   "source": [
    "class seq2seq(tf.keras.Model):\n",
    "    def __init__(self,input_vocab_size,output_vocab_size, embedding_dim, enc_dec_units, batch_sz,attention_mechanism):\n",
    "        super(seq2seq, self).__init__()\n",
    "        self.encoder = Encoder(input_vocab_size,embedding_dim,enc_dec_units,batch_sz)\n",
    "        self.decoder = Decoder(output_vocab_size,embedding_dim,enc_dec_units,batch_sz,attention_mechanism)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rhcHm2didmr"
   },
   "source": [
    "#### 1) dotproduct mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MwHhTNAFidmr"
   },
   "outputs": [],
   "source": [
    "seq2seqModel= seq2seq(INPUT_VOCAB_SIZE,OUTPUT_VOCAB_SIZE,ENCODE_EMBEDDING_DIM,ENCODER_UNITS,BATCH_SIZE,\"dotproduct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qg4Fpgxzidms"
   },
   "outputs": [],
   "source": [
    "encoder_dotproduct = seq2seqModel.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "liJLuHzQidms"
   },
   "outputs": [],
   "source": [
    "decoder_dotproduct = seq2seqModel.decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6QMOs72_2A1s"
   },
   "source": [
    "### 6）Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y9qeriTL2A1t"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp,tar,encoder,decoder):\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        encode_hidden = encoder.initialize_hidden_state()\n",
    "        encode_output,encode_hidden = encoder(inp,encode_hidden)\n",
    "\n",
    "        decode_hidden = encode_hidden\n",
    "\n",
    "        decode_input = tf.expand_dims([output_tokenizer.word_index['<start>']] * BATCH_SIZE,1)\n",
    "\n",
    "        for t in range(1,tar.shape[1]):\n",
    "            \n",
    "            predictions,decode_hidden,attention_weights = decoder(decode_input,decode_hidden,encode_output)\n",
    "\n",
    "            loss += loss_function(tar[:,t],predictions)\n",
    "            \n",
    "            decode_input = tf.expand_dims(tar[:, t], 1)\n",
    "        \n",
    "    batch_loss = (loss / int(tar.shape[1]))\n",
    "    \n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    \n",
    "    gradients = tape.gradient(loss,variables)\n",
    "    \n",
    "    \n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pkmf929D2A1x"
   },
   "outputs": [],
   "source": [
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FB4LG3d7j7ho"
   },
   "outputs": [],
   "source": [
    "def train_func(encoder,decoder,EPOCHS):\n",
    "    loss_list = []\n",
    "    for epoch in range(EPOCHS):\n",
    "        start = time.time()\n",
    "\n",
    "        total_loss = 0\n",
    "\n",
    "        for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "            batch_loss = train_step(inp,targ,encoder,decoder)\n",
    "            total_loss += batch_loss\n",
    "\n",
    "            if batch % 100 == 0:\n",
    "                print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,batch, batch_loss.numpy()))\n",
    "        \n",
    "        loss_list.append(total_loss.numpy() / steps_per_epoch)\n",
    "        \n",
    "        print('Epoch {} Loss {:.4f}'.format(epoch + 1,total_loss / steps_per_epoch))\n",
    "        print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n",
    "    return loss_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dn6f7WgqAdod"
   },
   "source": [
    "##### 1) Dotproduct Attention Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GnNAjOlojEs5",
    "outputId": "22abb4d0-4d8e-471c-e9ff-8bf5a78146e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 4.8733\n",
      "Epoch 1 Batch 100 Loss 2.3342\n",
      "Epoch 1 Batch 200 Loss 1.9543\n",
      "Epoch 1 Batch 300 Loss 2.0870\n",
      "Epoch 1 Batch 400 Loss 1.7715\n",
      "Epoch 1 Batch 500 Loss 1.8378\n",
      "Epoch 1 Batch 600 Loss 1.7443\n",
      "Epoch 1 Loss 2.0283\n",
      "Time taken for 1 epoch 91.51159715652466 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.5796\n",
      "Epoch 2 Batch 100 Loss 1.4832\n",
      "Epoch 2 Batch 200 Loss 1.5143\n",
      "Epoch 2 Batch 300 Loss 1.4006\n",
      "Epoch 2 Batch 400 Loss 1.3657\n",
      "Epoch 2 Batch 500 Loss 1.3932\n",
      "Epoch 2 Batch 600 Loss 1.3106\n",
      "Epoch 2 Loss 1.3958\n",
      "Time taken for 1 epoch 80.90127205848694 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.0648\n",
      "Epoch 3 Batch 100 Loss 0.9797\n",
      "Epoch 3 Batch 200 Loss 1.0977\n",
      "Epoch 3 Batch 300 Loss 1.0587\n",
      "Epoch 3 Batch 400 Loss 1.0382\n",
      "Epoch 3 Batch 500 Loss 0.9605\n",
      "Epoch 3 Batch 600 Loss 1.0748\n",
      "Epoch 3 Loss 1.0315\n",
      "Time taken for 1 epoch 80.95814895629883 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.8808\n",
      "Epoch 4 Batch 100 Loss 0.6992\n",
      "Epoch 4 Batch 200 Loss 0.8128\n",
      "Epoch 4 Batch 300 Loss 0.9684\n",
      "Epoch 4 Batch 400 Loss 0.7370\n",
      "Epoch 4 Batch 500 Loss 0.8631\n",
      "Epoch 4 Batch 600 Loss 0.8936\n",
      "Epoch 4 Loss 0.8592\n",
      "Time taken for 1 epoch 80.64899134635925 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.7818\n",
      "Epoch 5 Batch 100 Loss 0.7827\n",
      "Epoch 5 Batch 200 Loss 0.5623\n",
      "Epoch 5 Batch 300 Loss 0.6822\n",
      "Epoch 5 Batch 400 Loss 0.6245\n",
      "Epoch 5 Batch 500 Loss 0.5922\n",
      "Epoch 5 Batch 600 Loss 0.6349\n",
      "Epoch 5 Loss 0.6850\n",
      "Time taken for 1 epoch 80.46683239936829 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.5320\n",
      "Epoch 6 Batch 100 Loss 0.5372\n",
      "Epoch 6 Batch 200 Loss 0.5069\n",
      "Epoch 6 Batch 300 Loss 0.5512\n",
      "Epoch 6 Batch 400 Loss 0.5992\n",
      "Epoch 6 Batch 500 Loss 0.5450\n",
      "Epoch 6 Batch 600 Loss 0.6450\n",
      "Epoch 6 Loss 0.5401\n",
      "Time taken for 1 epoch 80.4117157459259 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.4504\n",
      "Epoch 7 Batch 100 Loss 0.3758\n",
      "Epoch 7 Batch 200 Loss 0.3795\n",
      "Epoch 7 Batch 300 Loss 0.4140\n",
      "Epoch 7 Batch 400 Loss 0.4699\n",
      "Epoch 7 Batch 500 Loss 0.5441\n",
      "Epoch 7 Batch 600 Loss 0.5054\n",
      "Epoch 7 Loss 0.4414\n",
      "Time taken for 1 epoch 80.30214715003967 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.2928\n",
      "Epoch 8 Batch 100 Loss 0.2799\n",
      "Epoch 8 Batch 200 Loss 0.5241\n",
      "Epoch 8 Batch 300 Loss 0.4747\n",
      "Epoch 8 Batch 400 Loss 0.3604\n",
      "Epoch 8 Batch 500 Loss 0.3552\n",
      "Epoch 8 Batch 600 Loss 0.4842\n",
      "Epoch 8 Loss 0.4145\n",
      "Time taken for 1 epoch 80.50323843955994 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.3268\n",
      "Epoch 9 Batch 100 Loss 0.2566\n",
      "Epoch 9 Batch 200 Loss 0.2709\n",
      "Epoch 9 Batch 300 Loss 0.3715\n",
      "Epoch 9 Batch 400 Loss 0.4231\n",
      "Epoch 9 Batch 500 Loss 0.3673\n",
      "Epoch 9 Batch 600 Loss 0.3582\n",
      "Epoch 9 Loss 0.3547\n",
      "Time taken for 1 epoch 80.49592614173889 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.3259\n",
      "Epoch 10 Batch 100 Loss 0.3159\n",
      "Epoch 10 Batch 200 Loss 0.2843\n",
      "Epoch 10 Batch 300 Loss 0.3976\n",
      "Epoch 10 Batch 400 Loss 0.2520\n",
      "Epoch 10 Batch 500 Loss 0.4405\n",
      "Epoch 10 Batch 600 Loss 0.2689\n",
      "Epoch 10 Loss 0.2960\n",
      "Time taken for 1 epoch 80.5306396484375 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_list_dotproduct = train_func(encoder_dotproduct,decoder_dotproduct,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k16ivEAyAcHF"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upvv2HFt_HNO"
   },
   "outputs": [],
   "source": [
    "def translate(sentence,encoder,decoder):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    inputs = [input_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],maxlen=max_length_input,padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "    encode_hidden = [tf.zeros((1,DECODER_UNITS))]\n",
    "    encode_output,encode_hidden = encoder(inputs,encode_hidden)\n",
    "    \n",
    "    decode_input = tf.expand_dims([output_tokenizer.word_index['<start>']],1)\n",
    "    decode_hidden = encode_hidden\n",
    "\n",
    "    predicted_ids = []\n",
    "    for t in range(max_length_targ):\n",
    "        \n",
    "        predictions,decode_hidden,attention_weights = decoder(decode_input,decode_hidden,encode_output)\n",
    "        \n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "        \n",
    "        predictions = predictions.numpy()\n",
    "        predicted_id = np.argmax(predictions[0])\n",
    "        \n",
    "        if output_tokenizer.index_word[predicted_id] == '<end>':\n",
    "            return result,attention_plot\n",
    "        else:\n",
    "            predicted_ids.append(predicted_id)\n",
    "\n",
    "        result = ' '.join([output_tokenizer.index_word[predicted_id] for predicted_id in predicted_ids])\n",
    "\n",
    "        decode_input = tf.expand_dims([predicted_id], 1)\n",
    "        \n",
    "    \n",
    "    return result,attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "inbhAKyD_U8F"
   },
   "outputs": [],
   "source": [
    "lines = io.open(path_to_file, encoding='UTF-8').read().strip().split('\\n')[:-1][:num_examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v3guLZ0U_K9R",
    "outputId": "20187612-e870-4671-b20c-e89277b7b879"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spanish:Es demasiado sensible.\n",
      "English:He is too sensitive.\n",
      "Translated Result:it s too sensitive .\n"
     ]
    }
   ],
   "source": [
    "random_sample = random.randint(0,len(lines))\n",
    "english, spanish  = lines[random_sample].split(\"\\t\")\n",
    "result,_ = translate(spanish,encoder_dotproduct,decoder_dotproduct)\n",
    "print(\"Spanish:%s\"%spanish)\n",
    "print(\"English:%s\"%english)\n",
    "print(\"Translated Result:%s\"%result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j0Nd8W1Z_XRh"
   },
   "outputs": [],
   "source": [
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 701
    },
    "id": "ZyvG5B87_NVL",
    "outputId": "641fad41-40c8-472c-e42f-de3fefdb3e47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spanish:Todavía estoy ocupada.\n",
      "English:I'm still busy.\n",
      "Translated Result:i m still busy .\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAJ5CAYAAABCAODaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAZnUlEQVR4nO3de7SlB1nf8d+TTBIwCAhBbk0IQiFYbrKmAgYjVgVRF22xlWoWCijRKIqLpeB1ibUtBhRRQSRyE0XiHbxVxSpSazANKBCBEIIQCyIBMQoEcnv6x95jxuNMmAlnzrvPeT6ftc7K2e/eZ/aTtWe++z3vfi/V3QFghuOWHgCAnSP6AIOIPsAgog8wiOgDDCL6AIOIPsAgog8wiOgDDCL6wGhVdeeqOm3pOXZKOQ0DMFlVvS3Jvbr7+KVn2Qn7lh4AYGHfneQ2Sw+xU6zpAwximz7AIDbvAGNU1ROSfHWS05KcePB93f1Ziwy1w6zpAyNU1Xcm+dEkb0hyepJXJbkkye2SvGS5yXaWbfrACFX1jiTf092/UlX/mOQB3f2uqvr+JKd195MWHnFHWNMHpvhXSS5af391kluvv39lkq9cZKIFiD4wxfuTnLL+/j1JHrr+/p5JxmzyEH1gij9M8uj19y9O8pyq+qMkv5jk1xabaofZpr8h7FUAx1ZVHZfkuO6+bn37sUnOTPKOJC/s7muXnG+nWNPfAPYqgGOvu284EPz17V/s7m/r7udNCX5iTX8j2KsAjo2qOutIH9vdrzuWs2wK0d8AVfWxJGd09xVV9YEkj+juv6iqeya5qLtvt/CIsCtV1Q1ZfUhb60UHgrf1dqaccM3mnc1grwI4Nu6Q5DPX//2KJJcm+dqs/m3dc/3923PjB7x7ntMwbIYDexW8Mau9Cn6sqr4qyYOS/NKSg8Fu1t0fOvB9Vf1Qkqd092sOesi71r9dPyvJb+/0fEuweWcD2KsAjr2qujrJg7r7bVuWf3aSN3T3LZeZbGeJ/gKq6iuT/Gl3/83Ss8AUVXVxkncmeUJ3X71edsskL01yz+7ev+R8O8XmnWUcn+R/V9WjuvuyqnrQTT24u9+4Q3PBXnZukt9K8t6qevN62f2SXJ/kyxebaodZ019IVX1pkud29xmH2MPgYD1lrwI41qrq5CRnJzljvehtSX6huz+63FQ7S/QXVFWnd/e7q+puN/W47n7PTs0E7G2ivwGq6vjuvn7pOWCvq6p9ST43hz7dycsXGWqHif4GqKork1yQ5Oe7+8+Wngf2oqo6I8lvJrl7VptSr8/qc81rk3yiu299Ez++Zzg4azN8b1YfKP1pVV1WVT+wPhoX2D7Pzer8VrdJ8rEk90myP8lfZND59K3pb5CqOjXJ16y/7pfVBR9+rrufv+hgsAdU1YeSfEF3X1JVVyX53O6+tKq+IMlPdvf9Fx5xR1jT3yDd/dfdfV53PyCrNZCTkvzEwmNxGFX1qqr6ivXBdWy+ymoNP0muTHLX9ff/L6tTMoxgP/0NU1UPy2qXsv+c1QdNP7/sRNyEj2Z1AY6rquplSV7a3ZctOxI34ZIkD0jyrqx+i356VV2f5ElZHbQ1gs07G6Cq/k1Wof/qrNY+XpNV7F914MhBNlNV3Tqr1+4JWf129idJXpTkl712m6WqHpnk5O7+tar6rKzOtXPvJB9M8lXd/dol59spor8B1gdnXZTkFUku6O4rFx6Jm2H95v0NSb4pySey+i3guVvP9cLmqKrbJflwDwqhzTub4d42C+xuVXWXJP8+q9P3XpfkV5OcmuTNVfXd3f0jS87Hjdbn27nH+ublk4KfWNOHm62qTsgq9E9M8iVJ/jzJzyR5ZXd/ZP2YRyd5eXffdrFBSZJU1UlJzkvyjVl9XlZZ/UZ2fpKnd/fHFxxvx1jT3wBVdWJW++ofuDD6CQff79w7G+tvsgrHLyT5ru5+8yEe87okH97RqTicFyR5RFab4C5cL3tokmcm+fSs3rz3PGv6G6Cqzkvy2Kz+8v1Yku/L6gLp/yXJ93f3C5ebjsOpqsdl9YHtiDXE3W59/enHbLmISqrqS5L86pQjckV/A1TVXyU5t7t/d/0X84HdfXlVnZvki7r7Py08Ijehqm6RGy9tebk3gc1UVe9P8u+6+61bln92kj/q7jsuM9nOclDJZrhjkgN/ET+S5MD239/N6tdRNlBV7auqZ2e1+eZNSd6S5MNV9az19n42y08m+YH1B7lJ/ulD3e9f3zeCbfqb4Yokd1n/951JHpnVOUIemsS+3pvrWVl9DvNNWe2fnySfn9VmuuOSfMdCc3FoD0nyBfmXF1HZl+TkqvqNAw/s7j17oXTR3wy/nuSLkrw+yY8neWVVPSmrA7WeveRg3KSvSfLE7v6dg5Zdvj5r6osi+pvmg1ntSnuwv1pikCXZpr+BquohST4vyTu6+7eWnodDW19o+4HdfemW5Wck+fMpF9pmdxF9uJmq6vVJ3tDd37Jl+QuyejN46DKTweGJ/kKq6muP9LFTruiz21TVWUl+J8l7s9o0l6y2G98lyaO6+08O97PsvKp6S1Z7WB3SlFMri/5C1rtmHuzErA7KumF9+7gMu6LPbrQ+/cK35J9faPunuvt9y03FoVTVD2xZdEKSByY5M8nzu/v7dn6qnSf6G6CqvjzJM5J8e5IDl0t8cJLnJPkh2/U3U1WdluSvD3Xulqo6rbuvWGAsjlJVfWeSu3X3k5eeZSeI/gaoqrdltRfIhVuWPzTJy7r73stMxk1Zn4v9zt39gS3Lb5/kA06fsTtU1T2SXNzdn7H0LDvBwVmb4fSsLsix1ceyOhcPm6ly6G3Et0riqNzd46zceEWtPc9++pvhz5L8RFWd3d3vTZKqumtW5+F5/U3+JDuuqg5cwrKTPLOqDg7G8Uk+N6uLbbNBDj746sCiJHdO8jlJfnDnJ1qG6G+Gr0/yqiTvrqr3rpfdNcmlSf7DYlNxOPdb/7eS3CfJNQfdd02SNyZx/vzN86Ett29I8pdJvqe7f3+BeRZhm/6GqKrK6pzsB+8F8gfTLvCwm1TVS5M8pbv/YelZ4EiJPmyT9cm7zkxyWXe/Z+l5+OfWl7M8fut1D6rq/kmu23r2zb3KB7kboqq+vKpeV1UfrKorq+qPq+rLlp6Lw6uql1XVN6+/PzGr6xz/fpJLq+pRiw7HoZyf5L6HWP7Z6/tGEP0NUFXfkNVJ1y5P8vQk35XViaB+vapGXM1nl3pkbvyg/dFZXX3pTlkdc/GMZUbiJtw/qzfmrf5vbvycZs/zQe5meHqSp3b38w5a9uKqekNWbwAvWWYsPonPSHJgH/0vzerqSx+oqguyuvwlm+X6JLc5xPLPyOpD+RGs6W+G07K6YMpW/zPJ3XZ4Fo7c+5Pct6qOz2qt/w/Wy2+V1Sk02Cx/nOR7169XktWFcLJ6g37dYlPtMGv6m+GKrPbceeeW5Y9I4gPBzfWSJL+Y5H1ZrUX+r/XyByd5+1JDcVhPy+piN++sqgMnw3tYVm/SZy021Q4T/QVV1UuSPCWrfbp/sqoelORP13efmeRxSb51ofH4JLr7v1bVJVn9NvZL3X1gf/3rkpy33GQcSndfut5T51uyOiArSV6RYSfIs3lnWV+X5Jbd/cIkj83qQJ8fWX+dkeSrunvMXgW71NVJvjjJa6rq1PWyE7O61jGb54b118ezOvXC9Vm9SY8h+sv6pw+PuvvXu/th3X379dfDuvvVSw7HTauqs5P8UpJ3JLl7VqfqTVb/rp621FwcWlWdmdUm1K/JKvgfT3J2Vpt7xlzwxsFZC6qqG5LcsbuvXHoWjl5VvSnJM7v7gvX1ER7Q3e+qqgck+f3uvuPCI3KQqrowyVuSfFN337BedlySn05y3+7+vCXn2ym26S/v/aszMByeU/RurH+d5MJDLP9IEhe+2TwPTPL4A8FPku6+oaqek+TPlxtrZ4n+8s5J8vdLD8HN8r4k98q/3MPqrKwOtGOzXJXVZrhLtyy/ewb9GxT95f3m1otwsGucn9Upsb9hffvUqvr8JM+KI3I30QVZHfT4tPzzveTOS/LKxabaYaK/LB+o7GLd/ayquk2S1yS5RZI/SvKJJD/S3c9fdDgO5WlZ7TzxktzYvmuTvCCrI99H8EHugtYf5N7Jmv7uVlWfltVJu45L8tbutrvmBlu/XvdY37y8u8dcNSsRfYBR7KcPMIjoAwwi+huqqs5ZegaOjtds95n4mon+5hr3l3EP8JrtPuNeM9EHGGTX771zyu2O79NPPeGTP3CXufJD1+cOt3f2hd1kL79ml11626VHOCauuf7qnHj8LZceY9tdfe1Vueb6qw95fpddf3DW6aeekIt+79RP/kDgZvuys/7j0iNwFC684uWHvc/mHYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGGRjo19VL6uq31p6DoC9ZN/SA9yEpySppYcA2Es2NvrdfdXSMwDsNTbvAAyysdEHYPvtyuhX1TlVdXFVXXzlh65fehyAXWNXRr+7z+/u/d29/w63P37pcQB2jV0ZfQBuHtEHGET0AQYRfYBBNvngrMcvPQPAXmNNH2AQ0QcYRPQBBhF9gEFEH2AQ0QcYRPQBBhF9gEFEH2AQ0QcYRPQBBhF9gEFEH2AQ0QcYRPQBBhF9gEFEH2AQ0QcYRPQBBhF9gEFEH2AQ0QcYRPQBBhF9gEFEH2AQ0QcYRPQBBhF9gEFEH2AQ0QcYRPQBBhF9gEFEH2AQ0QcYRPQBBhF9gEFEH2AQ0QcYRPQBBhF9gEFEH2AQ0QcYRPQBBhF9gEFEH2AQ0QcYRPQBBtm39ACfqrdfcUrOOvecpcfgKNzy1RctPQJH7a+WHoCj0H3NYe+zpg8wiOgDDCL6AIOIPsAgog8wiOgDDCL6AIOIPsAgog8wiOgDDCL6AIOIPsAgog8wiOgDDCL6AIOIPsAgog8wiOgDDCL6AIOIPsAgog8wiOgDDCL6AIOIPsAgog8wiOgDDCL6AIOIPsAgog8wiOgDDCL6AIOIPsAgog8wiOgDDCL6AIOIPsAgog8wiOgDDCL6AIOIPsAgog8wiOgDDCL6AIOIPsAgog8wiOgDDCL6AIOIPsAgog8wiOgDDCL6AIPsePSr6rVV9YKq+tGq+ruqurKqnlJVJ1XV86vq76vqiqp63E7PBrDXLbWmf3aSf0zy4CQ/nOS5SV6V5B1J9if52SQvqqo7LzQfwJ60VPT/sruf0d2XJXlOkg8muba7f7y735nkvyapJGcuNB/AnrRU9N984Jvu7iQfSPKWg5Zdm+TDST7zUD9cVedU1cVVdfF1n/josZ4VYM9YKvrXbrndh1l2yPm6+/zu3t/d+/eddPKxmA9gT7L3DsAgog8wiOgDDLJvp5+wux9+iGX3PcSyO+3IQACDWNMHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGGSx6FfVa6vqeUd6G4BP3b5j/QRV9fgkz+vuW2256zFJrj3Wzw/AjY559A+nu/9uqecGmGrbNu9U1VlV9fqq+khVXVVVF1XVk5O8NMnJVdXrr2esH2/zDcAO25Y1/aral+TVSV6c5OwkJyR5UJK/TPLtSf5HknusH/6R7XhOAI7edm3euXWS2yb5ze6+fL3s7UlSVZ+TpLv7/dv0XADcTNuyeWe9ff5lSX6vqn67qp5aVadtx599KFV1TlVdXFUXX/eJjx6rpwHYc7Ztm353PyHJg5O8Lsmjk1xaVY/crj9/y3Od3937u3v/vpNOPhZPAbAnbet++t39pu4+r7sfnuS1Sb4uyTVJjt/O5wHg5tmW6FfV3avqh6vq86rqblX1hUnun+StSd6d5BZV9SVVdUpVfdp2PCcAR2+7Psj9WJJ7JfnlJKck+dskr0hyXndfW1U/neSVSW6f5AeTPGObnheAo7At0e/uv83qCNvD3X9uknO3LHv40dwG4FPnhGsAg4g+wCCiDzCI6AMMIvoAg4g+wCCiDzCI6AMMIvoAg4g+wCCiDzCI6AMMIvoAg4g+wCCiDzCI6AMMIvoAg4g+wCCiDzCI6AMMIvoAg4g+wCCiDzCI6AMMIvoAg4g+wCCiDzCI6AMMIvoAg4g+wCCiDzCI6AMMIvoAg4g+wCCiDzCI6AMMIvoAg4g+wCCiDzCI6AMMIvoAg4g+wCCiDzCI6AMMIvoAg4g+wCCiDzCI6AMMIvoAg4g+wCCiDzCI6AMMIvoAg4g+wCCiDzCI6AMMIvoAg4g+wCCiDzCI6AMMIvoAg4g+wCCiDzCI6AMMIvoAg4g+wCCiDzCI6AMMIvoAg4g+wCCiDzCI6AMMIvoAg4g+wCCiDzCI6AMMIvoAg4g+wCCiDzCI6AMMIvoAg4g+wCCiDzCI6AMMIvoAg4g+wCCiDzCI6AMMIvoAg4g+wCCiDzCI6AMMIvoAg4g+wCCiDzCI6AMMIvoAg3zS6FfVa6vqeTsxDADHljV9gEFEH2CQI43+vqr68ar68Prr2VV1XJJU1bur6jsOfvDWTUJV9ZiqenNVXV1Vf1dVf1xVd6yq06vqhqrav+Xnn1RVH6yqEz/l/0MA/smRRv/s9WMfmuQbk5yT5NuP5Aer6k5JLkjys0nuk+SsJD+XJN397iSvSfLELT/2xCQ/193XHOF8AByBfUf4uL9J8m3d3UneXlX3SvLUJM85gp+9S5ITkvxKd79nveySg+7/mSQ/U1VP7e6PV9V9kjwkyZMO9wdW1TlZvfHkpFve9gj/FwA40jX916+Df8CFSe5aVbc+gp99U5I/SHJJVf1qVZ1bVXc46P5XJ7kmyWPWt5+Y5KLuviSH0d3nd/f+7t6/76STj/B/AYDt+CD3hiS1ZdkJB77p7uuTPGL99eYkX5/ksqp6wPr+a5O8PMkTq2pfksclefE2zAXAFkca/QdX1cFhf0iS93X3PyS5MsmdD9xRVbdIcsbBP9wrF3b3Dyb5t0nel+SxBz3kRUm+MMk3J/n0rD4DAGCbHek2/bskeW5V/VSS+yX5ziT/bX3fH2a1lv4bWb0BfO/Bf25VPSTJFyf5vSR/m+Rzkpya5K0HHtPdl1bVnyR5dpIL1m8mAGyzI43+K5Icn+TPknRWm19+bH3fM5OcntW2+Y8k+e9ZvUkccFWSM5N8a5LbJvnrJD/U3T+/5TlenNWePTbtABwjnzT63f3wg24++RD3/0OSr96y+KcOuv9tSR51BLPcOcll3f26I3gsADfDka7pHzNVdaskd0vylKx+SwDgGNmE0zA8L8kbk/yfJC9ceBaAPW3xNf3ufnySxy88BsAIm7CmD8AOEX2AQUQfYBDRBxhE9AEGEX2AQUQfYBDRBxhE9AEGEX2AQUQfYBDRBxhE9AEGEX2AQUQfYBDRBxhE9AEGEX2AQUQfYBDRBxhE9AEGEX2AQUQfYBDRBxhE9AEGEX2AQUQfYBDRBxhE9AEGEX2AQUQfYBDRBxhE9AEGEX2AQUQfYBDRBxhE9AEGEX2AQUQfYBDRBxhE9AEGEX2AQUQfYBDRBxhE9AEGEX2AQUQfYBDRBxhE9AEGEX2AQUQfYBDRBxhE9AEGEX2AQUQfYBDRBxhE9AEGEX2AQUQfYBDRBxhE9AEGEX2AQUQfYBDRBxhE9AEGEX2AQUQfYBDRBxhE9AEGEX2AQUQfYBDRBxhE9AEGEX2AQUQfYBDRBxhE9AEGEX2AQUQfYBDRBxhE9AEGEX2AQUQfYBDRBxhE9AEGEX2AQUQfYBDRBxhE9AEGEX2AQUQfYBDRBxhE9AEGEX2AQUQfYBDRBxhE9AEGEX2AQUQfYJBdGf2qOqeqLq6qi6/7xEeXHgdg19iV0e/u87t7f3fv33fSyUuPA7Br7MroA3DziD7AIBsb/ap6clW9fek5APaSjY1+klOS3HvpIQD2ko2Nfnc/o7tr6TkA9pKNjT4A20/0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBRB9gENEHGET0AQYRfYBBqruXnuFTUlVXJnnP0nMcA6ck+eDSQ3BUvGa7z159ze7W3Xc41B27Pvp7VVVd3N37l56DI+c1230mvmY27wAMIvoAg4j+5jp/6QE4al6z3Wfca2abPsAg1vQBBhF9gEFEH2AQ0QcYRPQBBvn/wqt5HYh1FIkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_sample = random.randint(0,len(lines))\n",
    "english, spanish  = lines[random_sample].split(\"\\t\")\n",
    "result,attention_plot = translate(spanish,encoder_dotproduct,decoder_dotproduct)\n",
    "print(\"Spanish:%s\"%spanish)\n",
    "print(\"English:%s\"%english)\n",
    "print(\"Translated Result:%s\"%result)\n",
    "attention_plot = attention_plot[:len(result.split(' ')), :len(spanish.split(' '))]\n",
    "plot_attention(attention_plot, spanish.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KlqD0d7yDu1L"
   },
   "source": [
    "##### 2) Bahdanau Attention Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j_KKolSLD-5S"
   },
   "outputs": [],
   "source": [
    "seq2seqModel= seq2seq(INPUT_VOCAB_SIZE,OUTPUT_VOCAB_SIZE,ENCODE_EMBEDDING_DIM,ENCODER_UNITS,BATCH_SIZE,\"Bahdanau\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XgYKW-W4EE3y"
   },
   "outputs": [],
   "source": [
    "encoder_Bahdanau = seq2seqModel.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "89r19Uz-EId2"
   },
   "outputs": [],
   "source": [
    "decoder_Bahdanau = seq2seqModel.decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7BbRpZ5_Ewln"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp,tar,encoder,decoder):\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        encode_hidden = encoder.initialize_hidden_state()\n",
    "        encode_output,encode_hidden = encoder(inp,encode_hidden)\n",
    "\n",
    "        decode_hidden = encode_hidden\n",
    "\n",
    "        decode_input = tf.expand_dims([output_tokenizer.word_index['<start>']] * BATCH_SIZE,1)\n",
    "\n",
    "        for t in range(1,tar.shape[1]):\n",
    "            \n",
    "            predictions,decode_hidden,attention_weights = decoder(decode_input,decode_hidden,encode_output)\n",
    "\n",
    "            loss += loss_function(tar[:,t],predictions)\n",
    "            \n",
    "            decode_input = tf.expand_dims(tar[:, t], 1)\n",
    "        \n",
    "    batch_loss = (loss / int(tar.shape[1]))\n",
    "    \n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    \n",
    "    gradients = tape.gradient(loss,variables)\n",
    "    \n",
    "    \n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7RFpFQjGELc2",
    "outputId": "695c7082-e233-4492-fc51-1c5898d325ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 4.8737\n",
      "Epoch 1 Batch 100 Loss 2.1003\n",
      "Epoch 1 Batch 200 Loss 1.7651\n",
      "Epoch 1 Batch 300 Loss 1.5895\n",
      "Epoch 1 Batch 400 Loss 1.2370\n",
      "Epoch 1 Batch 500 Loss 1.2626\n",
      "Epoch 1 Batch 600 Loss 1.0943\n",
      "Epoch 1 Loss 1.6076\n",
      "Time taken for 1 epoch 93.7564263343811 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.0543\n",
      "Epoch 2 Batch 100 Loss 0.9748\n",
      "Epoch 2 Batch 200 Loss 0.7767\n",
      "Epoch 2 Batch 300 Loss 0.6984\n",
      "Epoch 2 Batch 400 Loss 0.7408\n",
      "Epoch 2 Batch 500 Loss 0.5344\n",
      "Epoch 2 Batch 600 Loss 0.6508\n",
      "Epoch 2 Loss 0.8120\n",
      "Time taken for 1 epoch 83.67918491363525 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.4954\n",
      "Epoch 3 Batch 100 Loss 0.6069\n",
      "Epoch 3 Batch 200 Loss 0.5464\n",
      "Epoch 3 Batch 300 Loss 0.3767\n",
      "Epoch 3 Batch 400 Loss 0.5286\n",
      "Epoch 3 Batch 500 Loss 0.4499\n",
      "Epoch 3 Batch 600 Loss 0.4251\n",
      "Epoch 3 Loss 0.4684\n",
      "Time taken for 1 epoch 83.68306112289429 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.2458\n",
      "Epoch 4 Batch 100 Loss 0.3195\n",
      "Epoch 4 Batch 200 Loss 0.2673\n",
      "Epoch 4 Batch 300 Loss 0.3584\n",
      "Epoch 4 Batch 400 Loss 0.2774\n",
      "Epoch 4 Batch 500 Loss 0.3024\n",
      "Epoch 4 Batch 600 Loss 0.2938\n",
      "Epoch 4 Loss 0.2888\n",
      "Time taken for 1 epoch 83.73091530799866 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.1766\n",
      "Epoch 5 Batch 100 Loss 0.1248\n",
      "Epoch 5 Batch 200 Loss 0.1794\n",
      "Epoch 5 Batch 300 Loss 0.1882\n",
      "Epoch 5 Batch 400 Loss 0.1839\n",
      "Epoch 5 Batch 500 Loss 0.1880\n",
      "Epoch 5 Batch 600 Loss 0.2021\n",
      "Epoch 5 Loss 0.1897\n",
      "Time taken for 1 epoch 84.00791120529175 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.1384\n",
      "Epoch 6 Batch 100 Loss 0.0939\n",
      "Epoch 6 Batch 200 Loss 0.0959\n",
      "Epoch 6 Batch 300 Loss 0.1592\n",
      "Epoch 6 Batch 400 Loss 0.1633\n",
      "Epoch 6 Batch 500 Loss 0.1342\n",
      "Epoch 6 Batch 600 Loss 0.1636\n",
      "Epoch 6 Loss 0.1380\n",
      "Time taken for 1 epoch 83.82524251937866 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.0988\n",
      "Epoch 7 Batch 100 Loss 0.0799\n",
      "Epoch 7 Batch 200 Loss 0.1002\n",
      "Epoch 7 Batch 300 Loss 0.1182\n",
      "Epoch 7 Batch 400 Loss 0.1200\n",
      "Epoch 7 Batch 500 Loss 0.1074\n",
      "Epoch 7 Batch 600 Loss 0.1384\n",
      "Epoch 7 Loss 0.1086\n",
      "Time taken for 1 epoch 83.76697731018066 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.0575\n",
      "Epoch 8 Batch 100 Loss 0.0691\n",
      "Epoch 8 Batch 200 Loss 0.0721\n",
      "Epoch 8 Batch 300 Loss 0.0988\n",
      "Epoch 8 Batch 400 Loss 0.0916\n",
      "Epoch 8 Batch 500 Loss 0.0697\n",
      "Epoch 8 Batch 600 Loss 0.0914\n",
      "Epoch 8 Loss 0.0882\n",
      "Time taken for 1 epoch 83.59918212890625 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.0579\n",
      "Epoch 9 Batch 100 Loss 0.1010\n",
      "Epoch 9 Batch 200 Loss 0.0614\n",
      "Epoch 9 Batch 300 Loss 0.0433\n",
      "Epoch 9 Batch 400 Loss 0.0750\n",
      "Epoch 9 Batch 500 Loss 0.0778\n",
      "Epoch 9 Batch 600 Loss 0.0759\n",
      "Epoch 9 Loss 0.0761\n",
      "Time taken for 1 epoch 83.89819192886353 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.0520\n",
      "Epoch 10 Batch 100 Loss 0.0648\n",
      "Epoch 10 Batch 200 Loss 0.0872\n",
      "Epoch 10 Batch 300 Loss 0.0682\n",
      "Epoch 10 Batch 400 Loss 0.0919\n",
      "Epoch 10 Batch 500 Loss 0.0785\n",
      "Epoch 10 Batch 600 Loss 0.0789\n",
      "Epoch 10 Loss 0.0681\n",
      "Time taken for 1 epoch 83.77131295204163 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_list_Bahdanau = train_func(encoder_Bahdanau,decoder_Bahdanau,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 678
    },
    "id": "uylgpKoxMOJL",
    "outputId": "8b3a1d13-8524-4d35-9694-97799aaaaae4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spanish:Cierra el gas.\n",
      "English:Turn off the gas.\n",
      "Translated Result:turn off the gas .\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_sample = random.randint(0,len(lines))\n",
    "english, spanish  = lines[random_sample].split(\"\\t\")\n",
    "result,attention_plot = translate(spanish,encoder_Bahdanau,decoder_Bahdanau)\n",
    "print(\"Spanish:%s\"%spanish)\n",
    "print(\"English:%s\"%english)\n",
    "print(\"Translated Result:%s\"%result)\n",
    "attention_plot = attention_plot[:len(result.split(' ')), :len(spanish.split(' '))]\n",
    "plot_attention(attention_plot, spanish.split(' '), result.split(' '))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "8u-W9w2VTJdm",
    "outputId": "48f822bb-bcaa-4c30-85a9-e0c69571d52d"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "l1 = plt.plot(loss_list_dotproduct,label =\"dotProduct Attention\")\n",
    "l2 = plt.plot(loss_list_Bahdanau,label =\"Bahdanau Attention\")\n",
    "plt.xlabel(\"Epoch\",fontsize='small')\n",
    "plt.ylabel(\"Loss\",fontsize='small')\n",
    "plt.legend(loc='best')\n",
    "plt.title(\"DotProduct VS Bahdanau\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./AttentionComparison.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Seq2Seq_Attention_Comparison.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
